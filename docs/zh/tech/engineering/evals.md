# 评估 (Evals)

你无法改进你无法衡量的东西。**Evals** 是 AI 质量的“单元测试”。

## 核心 RAG 指标 (RAG 三元组)

在构建 RAG 时，你需要衡量三件事：

1.  **上下文相关性 (Context Relevance)**: 我找到了正确的文件吗？(检索器质量)
2.  **忠实度 (Faithfulness)**: AI 是否*仅*根据文档回答？(幻觉检查)
3.  **答案相关性 (Answer Relevance)**: AI 实际上回答了用户的问题吗？

## 如何衡量？

由于“质量”是主观的，我们使用更强的 LLM (GPT-4) 来给较弱的 LLM 打分。

### 示例：忠实度检查

```
System: 你是一个严格的评分员。
User:
Context: "Apple 成立于 1976 年。"
Answer: "Apple 成立于 1990 年。"

Answer 是否与 Context 一致？
分数 (0-1):
```

## A/B 测试提示词

在没有 A/B 测试的情况下，永远不要在生产环境中更改提示词。

1.  **基线 (Baseline)**: 当前提示词 A。
2.  **挑战者 (Challenger)**: 新提示词 B (例如，“更简洁”)。
3.  **实验**: 将 50% 的流量路由到 B。
4.  **指标**: 衡量“复制按钮点击率”或“点赞率”。

## 用户反馈循环

最有价值的数据是显式用户反馈。

- 👍 **正面**: 将此对话添加到你的“黄金数据集”中，以备将来微调。
- 👎 **负面**: 将此添加到你的“回归测试套件”中，以确保你修复了该 Bug。

## 工具

1.  **Ragas**: 用于计算 RAG 分数的 Python/JS 库。
2.  **Arize Phoenix**: 开源可观测性和评估平台。
3.  **LangSmith**: LangChain 的企业平台。