/**
 * è¿™ä¸ªæ–‡ä»¶æ¼”ç¤ºäº†å¦‚ä½•è®¡ç®—æ–‡æœ¬å‘é‡çš„ç›¸ä¼¼åº¦ï¼ˆEmbedding æ ¸å¿ƒåŸç†ï¼‰
 */

// æˆ‘ä»¬æ¨¡æ‹Ÿå¤§æ¨¡å‹ç”Ÿæˆçš„ 3 ç»´ç‰¹å¾å‘é‡ï¼ˆçœŸå®ä¸­é€šå¸¸æ˜¯ 1536 ç»´ç­‰ï¼‰
// å‡è®¾ä¸‰ä¸ªç»´åº¦ä»£è¡¨: [æ°´æœå±æ€§, ç§‘æŠ€å±æ€§, äº¤é€šå·¥å…·å±æ€§]
const embeddings: Record<string, number[]> = {
  apple: [0.9, 0.1, 0.0],
  orange: [0.8, 0.0, 0.0],
  computer: [0.0, 0.9, 0.1],
  car: [0.0, 0.1, 0.9],
};

// è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦ (Cosine Similarity)
function cosineSimilarity(vecA: number[], vecB: number[]): number {
  let dotProduct = 0;
  let normA = 0;
  let normB = 0;
  for (let i = 0; i < vecA.length; i++) {
    dotProduct += vecA[i] * vecB[i];
    normA += vecA[i] ** 2;
    normB += vecB[i] ** 2;
  }
  if (normA === 0 || normB === 0) return 0;
  return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
}

console.log("ğŸŒŒ å‘é‡ç›¸ä¼¼åº¦ (Embedding) æ¼”ç¤ºå®éªŒ\n");
console.log(
  "åœ¨è¿™ä¸ªå®éªŒä¸­ï¼Œæˆ‘ä»¬é¢„å®šä¹‰äº†ä¸€äº›è¯çš„ç‰¹å¾å‘é‡ï¼Œç”¨æ¥æ¨¡æ‹Ÿå¤§æ¨¡å‹çš„ Embedding ç»“æœã€‚",
);

const comparisons = [
  { word1: "apple", word2: "orange", desc: "è‹¹æœ vs æ©˜å­ (åŒç±»)" },
  { word1: "apple", word2: "computer", desc: "è‹¹æœ vs ç”µè„‘ (éåŒç±»)" },
  { word1: "car", word2: "computer", desc: "æ±½è½¦ vs ç”µè„‘" },
];

comparisons.forEach(({ word1, word2, desc }) => {
  const vec1 = embeddings[word1];
  const vec2 = embeddings[word2];
  const similarity = cosineSimilarity(vec1, vec2);

  console.log(`ã€${desc}ã€‘`);
  console.log(`  ${word1} å‘é‡: [${vec1.join(", ")}]`);
  console.log(`  ${word2} å‘é‡: [${vec2.join(", ")}]`);
  console.log(`  ğŸ’¡ ä½™å¼¦ç›¸ä¼¼åº¦: ${(similarity * 100).toFixed(2)}%\n`);
});

console.log(
  "ğŸ“Œ ç»“è®º: Semantic ç›¸ä¼¼çš„æ„æ€åœ¨å¤šç»´ç©ºé—´ä¸­æ€»æ˜¯æ›´é è¿‘å½¼æ­¤ã€‚è¿™ä¹Ÿæ˜¯åŸºäºå‘é‡çš„ RAG æ£€ç´¢çš„æ ¸å¿ƒåŸºç¡€ï¼",
);
