import { get_encoding } from "tiktoken";

// ä½¿ç”¨ cl100k_base ç¼–ç ï¼Œè¿™æ˜¯ GPT-3.5 å’Œ GPT-4 ä½¿ç”¨çš„ç¼–ç å™¨
const encoding = get_encoding("cl100k_base");

function analyzeToken(text: string, description: string) {
  const tokens = encoding.encode(text);
  console.log(`\n=== ${description} ===`);
  console.log(`æ–‡æœ¬å†…å®¹: "${text}"`);
  console.log(`Token æ•°é‡: ${tokens.length}`);
  console.log(`å­—ç¬¦é•¿åº¦: ${text.length}`);
  // è¾“å‡ºå…·ä½“çš„ token id ä»¥åŠå®ƒä»¬å¯¹åº”çš„æ–‡æœ¬ç‰‡æ®µï¼ˆä¸ºäº†ç›´è§‚å±•ç¤ºï¼‰
  console.log(`Token æ‹†è§£:`);
  tokens.forEach((token) => {
    // tiktoken åœ¨è§£ç å•ä¸ª token æ—¶å¯èƒ½ä¼šæŠ¥é”™æˆ–è€…ä¸èƒ½å®Œç¾è¿˜åŸå¤šå­—èŠ‚å­—ç¬¦ï¼Œè¿™é‡Œç®€å•å±•ç¤º
    const tokenBytes = encoding.decode_single_token_bytes(token);
    let tokenString;
    try {
      tokenString = new TextDecoder().decode(tokenBytes);
    } catch {
      tokenString = "<ä¸å¯æ‰“å°å­—ç¬¦>";
    }
    console.log(`  [${token}] -> '${tokenString}'`);
  });
}

console.log("ğŸš€ æ¬¢è¿ä½“éªŒ Tokenizer æ¼”ç¤ºç¨‹åº\n");
console.log(
  "è¿™æ¼”ç¤ºäº†å¤§æ¨¡å‹ï¼ˆå¦‚ ChatGPTï¼‰æ˜¯å¦‚ä½•å°†è‡ªç„¶è¯­è¨€æ–‡æœ¬åˆ‡å‰²ä¸ºåŸºç¡€å¤„ç†å•å…ƒï¼ˆTokenï¼‰çš„ã€‚",
);

analyzeToken("Hello world!", "çº¯è‹±æ–‡ç¤ºä¾‹");
analyzeToken("è¿™æ˜¯ä¸€æ®µä¸­æ–‡æµ‹è¯•æ–‡æœ¬ã€‚", "çº¯ä¸­æ–‡ç¤ºä¾‹");
analyzeToken("Vibe Coding è®©ç¼–ç¨‹æ›´æœ‰æ„æ€ï¼", "ä¸­è‹±æ–‡æ··åˆç¤ºä¾‹");

// è®°å¾—é‡Šæ”¾å†…å­˜
encoding.free();
