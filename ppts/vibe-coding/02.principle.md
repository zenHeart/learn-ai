---
layout: full-vibe
class: p-0
clicks: 9
---

<VibeWorkflow />

<!--
这各交互图说明了整个 AI Coding 的核心工作流程也概括了我们日常的交互逻辑，简要说明下如何看懂这张图，图片包括三大块
1. 最顶部的是控制按钮，可以一步一步观察整个流转过程，点击重置复位到第一步
2. 中间为整个核心的 Ai Coding 工具完成任务的循环
3. 下边提示栏说明了当前这一步具体的工作内容，右侧的**小框** 表示当前这步给 Ai 的具体输入是什么，也可以理解为整个传递 Ai 大模型的所有信息，更专业的术语我们叫做 Context WIndow(上下文窗口)

整个核心循环讲完预计 10 分钟，只是课程重点需要询问大家是否有问题
-->

---
layout: vibe-step
activeStep: start
---

## User Prompt: 意图注入

<v-clicks>

1. **Prompt** 用户给大模型的输入
3. **Prompt Engineering(PE)** 优化 Prompt 控制大模型输出的方法叫提示词工程
4. **Session/Chat** 大模型本身是无状态的，AI 工具通过 Session/Chat 存储对话上下文(一般是 markdown 文件或 json 对象)

</v-clicks>


<v-click>

<div class="grid grid-cols-2">

<div class="flex flex-col">

1. **[Token](https://cursor.com/learn/tokens-pricing#understanding-tokens)** 大模型处理信息的最小文本单元 <VibeExample id="2.1" />
   - **Input Token**: 输入给大模型的 token。AI Coding工具（如Cursor）通常会实现上下文缓存机制以降低成本，应避免频繁变化的内容导致缓存失效。
   - **Output Token**: 大模型输出的 token。计算成本通常比输入 token 贵 2-4 倍。

</div>

<iframe
  src="https://gpt-tokenizer.dev/"
  class="w-full h-80 border-none rounded-lg shadow-lg"
/>

</div>

</v-click>

---
layout: vibe-step
activeStep: gather
---

## Gather Context: 语境收集


1. **Context Window (上下文窗口)**：大模型能处理的最大 Token 数量,
   * <span v-mark.underline.red> 注意上下文窗口大小是**输入 token** + **输出 token**</span> 
    <img src="/context-window.svg" alt="上下文窗口" class="h-70 mx-auto" />

<v-clicks>

2. **[Retrieval Augmented Generation(RAG)](https://arxiv.org/abs/2005.11401v4)** 提取增强生成，通过外挂知识库解决模型存在幻觉和知识更新不及时的问题 延伸阅读 [How Cursor Indexes Codebases Fast](https://read.engineerscodex.com/p/how-cursor-indexes-codebases-fast)
   * **[Embeddings(嵌入)](https://developers.google.com/mace-learning/crash-course/embeddings/embedding-space?hl=zh-cn)** 将文本/图片/音频/视频转换为向量数据的技术 <VibeExample id="2.2" />

</v-clicks>

---
layout: vibe-step
activeStep: llm
clicks: 3
---

## LLM Reasoning: 推理与规划

<div v-click="1">

1. **神经元** 模拟人类神经元工作原理的基本计算单元
   * 模型大小就是 权重(w) + 偏置(b) 的总和， 比如 4B 模型 就是 40 亿个参数
</div>

<div v-click="2">

1. **神经网络** 是一种计算模型，由多个神经元组成

</div>

<!--

### Transformer 概念详解（对照右侧示意图，从上往下看）

**1. Input（输入 token）**
电脑不认识文字，所以先把一句话切成小片段。
例如："我喜欢编程" → ["我", "喜欢", "编程"]
每个片段叫一个 token，再把每个 token 转成一串数字（比如 512 个数字），这串数字叫「词向量」。
图中顶部的彩色小方块就是一个个 token。

**2. Positional Encoding（位置编码）**
❓ 为什么需要它？
Transformer 和人类不同——人类是一个字一个字顺序读的，但 Transformer 是"同时看到所有字"。
所以它分不清"我喜欢你"和"你喜欢我"，因为两句话包含的词完全一样！

📌 它是怎么做的？
不是贴一个简单的编号，而是生成一组和词向量一样长的数字（也是 512 个），然后和词向量逐位相加：
词向量："我" → [0.2, 0.5, -0.1, ...]（512个数字）
位置编码：第1位 → [0.0, 0.01, 0.84, ...]（512个数字）
最终输入 = [0.2, 0.51, 0.74, ...]（逐位相加，还是512个数字）

效果：同一个词出现在不同位置，输入给模型的数据就会有细微差异，模型就能区分顺序了。

**3. Multi-Head Attention（多头注意力）— 图中橙色框**
🔍 一句话定义：让每个词去"打听"其他所有词——你跟我什么关系？关系越大，我越关注你。

怎么打听？通过三个角色：
- **Q（Query，提问者）**：我想知道什么？
- **K（Key，标签）**：我能提供什么信息？（别人身上的标签）
- **V（Value，内容）**：我的具体内容是什么？

例子："小猫坐在垫子上，它很舒服"
当处理"它"这个词时，Q 会和所有词的 K 比较，发现和"小猫"的相关性最高 → 于是获取"小猫"的 V（内容），从而理解"它=小猫"。

为什么叫"多头"？
就像老师改作文时，同时从语法、逻辑、情感、修辞四个角度打分。
每个"头"关注不同维度的关系，合在一起理解得更全面。

**4. Masked Multi-Head Attention（掩码注意力）— 图中黄色框**
🙈 和上面的多头注意力一样，但有个限制：只能往前看，不能偷看后面的词。

为什么？因为 Decoder 的任务是"一个字一个字往下写"。
写到第 3 个字时，第 4、5 个字还没生成呢，当然不能看！
"掩码"就是用一个遮罩把后面的位置挡住。

类比：考试写作文时，你只能参考已经写好的前文，不能偷看还没写的部分。

**5. Cross Multi-Head Attention（交叉注意力）— 图中 Decoder 内的橙色框**
🔗 这是 Encoder 和 Decoder 之间的"信息桥梁"。

工作方式：
- Decoder 带着 Q（"我现在要生成什么词？"）
- 去 Encoder 那里查找 K 和 V（"原文里有什么相关信息？"）

图中 Encoder 和 Decoder 之间标注了"K, V"箭头，就是这个意思——
Encoder 把理解结果（K 和 V）传给 Decoder，Decoder 根据需要去检索。

类比：写答案时回头翻题目，找相关的关键句。

**6. Feed-Forward Network（前馈网络）— 图中绿色框**
🧠 注意力让词和词之间互相交流后，每个词再单独"消化"一下。

它是两层简单的全连接网络（就是神经元那张图里的结构！）。
每个词独立地做一次非线性变换——类似于：小组讨论完之后，每个同学自己再想一想、总结一下。

**7. Add & Norm — 图中灰色小条 + 右侧虚线**
这是一个"保险机制"，每一层都有：

- **Add（残差连接）**：把这一层的"原始输入"直接加到"处理后的输出"上。
  类比：抄作业时，不管你改了什么，都把原文也保留一份。
  作用：防止信息在层层传递中丢失。图中右侧的虚线就是这条"捷径"。

- **Norm（层归一化）**：把数据"拉回正常范围"，不让数字变得太大或太小。
  类比：考试阅卷时统一评分标准，避免分数飘忽不定。

**8. Linear + Softmax（输出层）— 图中底部紫色框**
📊 最后一步：选词输出。

- **Linear**：把 Decoder 的输出映射到整个词表（比如 3 万个词）。每个词得到一个分数。
- **Softmax**：把分数转成概率（所有概率加起来 = 100%）。分数最高的词就是预测结果。

图中底部的彩色柱状就是概率分布——柱子越高，这个词被选中的概率越大。

| | Encoder（编码器） | Decoder（解码器） |
|---|---|---|
| 类比 | 读题、理解题意 | 写答案 |
| 注意力方向 | **双向**（每个词能看到所有词） | **单向**（只能看到前面的词） |
| 目标 | 理解输入的完整语义 | 一个一个地生成输出 |
| 代表模型 | BERT | GPT、Claude、LLaMA |

### 🚀 为什么 GPT/Claude 等 LLM 只用 Decoder（解码器）？

- **Encoder 像「学霸做阅读理解」** — 能前后看，全面理解，但只能回答选择题/填空题（理解类任务）
- **Decoder 像「即兴演讲者」** — 只能往前说，说到哪算哪，但能无限发挥、自由生成

为什么选 Decoder？因为我们需要 AI **生成**新内容（写代码、写文章、对话），而不仅仅是理解已有文本。

**三个关键原因：**
1. **生成任务的本质** — 写作就是"一个字接一个字往下写"，天然是单向的，跟 Decoder 的工作方式完全一致
2. **更容易扩大规模** — Decoder-only 结构更简单，更容易堆叠到数千亿参数
3. **大力出奇迹** — 研究发现，当数据和参数足够多时，Decoder 也能学会"理解"（虽然它只能往前看，但它已经读过海量文本，早就"理解"了）

### 📚 BERT 和 Transformer 的关系

**BERT 完全基于 Transformer！** 只不过它只用了 Encoder（左半部分）。

你可以这样记：
- **BERT = Transformer 的「阅读理解」部分** — 擅长理解，能做分类、判断、提取信息
- **GPT = Transformer 的「写作文」部分** — 擅长生成，能写文章、写代码、聊天

BERT 的特色是「完形填空式训练」：随机挖掉句子里 15% 的词，让模型猜被挖掉的词是什么。因为可以前后看，所以猜词很准，理解力强——但因为训练方式不是"往下写"，所以不擅长生成连贯的长文本。

-->

<div v-click="3">

3. **[Transformer 架构](https://arxiv.org/abs/1706.03762)** 通过**注意力机制**让每个词"关注"其他词，**基于概率预测生成下一个token**（而非真正"理解"语义），[交互示意图](https://bbycroft.net/llm) <VibeExample id="2.3" />  **Encoder** 「读题」— 双向阅读全文，理解输入的完整含义， **Decoder** 「写答案」— 逐字生成输出（GPT/Claude 只用这部分）

</div>

<LLMConcepts :activeCount="$clicks" />

<!--
1. 神经元由
   1. 输入(x1,x2,x3)
   2. 参数(权重 w1,w2,w3 + 偏置 b)
   3. 激活函数()
    4. 输出
2. 多个神经元构成神经网络，神经网络本质是一个预测模型，基于预训练的数据结果，来对新的数据进行预测
3. transformer 是一种神经网络的架构，核心创新在于注意力机制和并行计算
-->

---
layout: vibe-step
activeStep: action
---

## Take Action: 执行行动

<v-click>

1. **工具调用 (Tool Use / Function Calling)** <VibeExample id="2.4" />
   
| 工具 | 对应操作 |
|:---|:---|
|**read_file** | 读文件 |
|**write_file** | 写文件 |
|**glob** | 搜索文件|
|**web_fetch** | web 搜索
| **bash** | 内部集成大量工具 |

</v-click>

<v-click>

2. **mode** 模型执行的不同的模式：
   - **plan**: 模型先输出计划，用户确认后才执行
   - **edit**: 执行任务，每个权限需要用户确认
   - **yolo**: 自动执行任务，无人为接入

</v-click>

---

## 总结 Vibe Coding 的核心原理

<div class="grid grid-cols-3 gap-6 mt-8">

<div v-click class="p-6 rounded-xl bg-blue-500/10 border border-blue-500/30 text-center">

### 🎯 意图注入

**Prompt + Context Window**

用有限的上下文窗口，精准传递意图

</div>

<div v-click class="p-6 rounded-xl bg-purple-500/10 border border-purple-500/30 text-center">

### 🧠 概率推理

**Transformer 架构**

基于注意力机制的概率预测，存在幻觉和知识非最新问题

</div>

<div v-click class="p-6 rounded-xl bg-green-500/10 border border-green-500/30 text-center">

### 🔄 闭环迭代

**Tool Use + Agent**

工具调用 + 验证反馈，把不确定变为可收敛

</div>

</div>

<div v-click class="mt-8 p-4 rounded-lg bg-yellow-500/10 border border-yellow-500/20 text-center text-lg">

💡 核心本质：在<strong>概率预测</strong>之上，通过<strong>上下文建模</strong>与<strong>工具增强</strong>，结合 Agent 闭环迭代，<br/>把<strong>不确定生成</strong>转化为<strong>可验证、可收敛</strong>的工程过程。

</div>

<!--
这里总计花费 19 分钟， 需要向用户询问还有哪些问题，确保能够顺利的进入下一章讲解
-->
