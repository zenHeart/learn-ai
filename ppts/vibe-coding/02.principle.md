---
layout: full-vibe
---

<VibeWorkflow />

---
layout: vibe-step
activeStep: start
---

## User Prompt: 意图注入

1. **Prompt** 用户给大模型的输入
2. **Prompt Engineering(PE)** 优化 Prompt 控制大模型输出的方法叫提示词工程
3. **Token** 大模型处理信息的最小文本单元


<iframe 
  src="https://gpt-tokenizer.dev/" 
  class="w-full h-100 border-none rounded-lg shadow-lg"
  style="transform: scale(0.8); transform-origin: 0 0;"
/>

---
layout: vibe-step
activeStep: gather
---

## Gather Context: 语境收集

1. **Context Window (上下文窗口)**：大模型能处理的最大 Token 数量
    <img src="/context-window.svg" alt="上下文窗口" class="h-70 mx-auto" />
2. **[Embeddings(嵌入)](https://developers.google.com/mace-learning/crash-course/embeddings/embedding-space?hl=zh-cn)** 将文本/图片/音频/视频转换为向量数据的技术
3. **[Retrieval Augmented Generation(RAG)](https://arxiv.org/abs/2005.11401v4)** 结合嵌入与大模型，从外部数据源检索信息，帮助模型生成更准确结果的技术, 延伸阅读 [How Cursor Indexes Codebases Fast](https://read.engineerscodex.com/p/how-cursor-indexes-codebases-fast)

---
layout: vibe-step
activeStep: llm
clicks: 3
---

## LLM Reasoning: 推理与规划

<div v-click="1">

1. **神经元** 模拟人类神经元工作原理的基本计算单元

</div>

<div v-click="2">

2. **神经网络** 是一种计算模型，由多个神经元组成

</div>

<!--

### Transformer 概念详解（对照右侧示意图，从上往下看）

**1. Input（输入 token）**
电脑不认识文字，所以先把一句话切成小片段。
例如："我喜欢编程" → ["我", "喜欢", "编程"]
每个片段叫一个 token，再把每个 token 转成一串数字（比如 512 个数字），这串数字叫「词向量」。
图中顶部的彩色小方块就是一个个 token。

**2. Positional Encoding（位置编码）**
❓ 为什么需要它？
Transformer 和人类不同——人类是一个字一个字顺序读的，但 Transformer 是"同时看到所有字"。
所以它分不清"我喜欢你"和"你喜欢我"，因为两句话包含的词完全一样！

📌 它是怎么做的？
不是贴一个简单的编号，而是生成一组和词向量一样长的数字（也是 512 个），然后和词向量逐位相加：
词向量："我" → [0.2, 0.5, -0.1, ...]（512个数字）
位置编码：第1位 → [0.0, 0.01, 0.84, ...]（512个数字）
最终输入 = [0.2, 0.51, 0.74, ...]（逐位相加，还是512个数字）

效果：同一个词出现在不同位置，输入给模型的数据就会有细微差异，模型就能区分顺序了。

**3. Multi-Head Attention（多头注意力）— 图中橙色框**
🔍 一句话定义：让每个词去"打听"其他所有词——你跟我什么关系？关系越大，我越关注你。

怎么打听？通过三个角色：
- **Q（Query，提问者）**：我想知道什么？
- **K（Key，标签）**：我能提供什么信息？（别人身上的标签）
- **V（Value，内容）**：我的具体内容是什么？

例子："小猫坐在垫子上，它很舒服"
当处理"它"这个词时，Q 会和所有词的 K 比较，发现和"小猫"的相关性最高 → 于是获取"小猫"的 V（内容），从而理解"它=小猫"。

为什么叫"多头"？
就像老师改作文时，同时从语法、逻辑、情感、修辞四个角度打分。
每个"头"关注不同维度的关系，合在一起理解得更全面。

**4. Masked Multi-Head Attention（掩码注意力）— 图中黄色框**
🙈 和上面的多头注意力一样，但有个限制：只能往前看，不能偷看后面的词。

为什么？因为 Decoder 的任务是"一个字一个字往下写"。
写到第 3 个字时，第 4、5 个字还没生成呢，当然不能看！
"掩码"就是用一个遮罩把后面的位置挡住。

类比：考试写作文时，你只能参考已经写好的前文，不能偷看还没写的部分。

**5. Cross Multi-Head Attention（交叉注意力）— 图中 Decoder 内的橙色框**
🔗 这是 Encoder 和 Decoder 之间的"信息桥梁"。

工作方式：
- Decoder 带着 Q（"我现在要生成什么词？"）
- 去 Encoder 那里查找 K 和 V（"原文里有什么相关信息？"）

图中 Encoder 和 Decoder 之间标注了"K, V"箭头，就是这个意思——
Encoder 把理解结果（K 和 V）传给 Decoder，Decoder 根据需要去检索。

类比：写答案时回头翻题目，找相关的关键句。

**6. Feed-Forward Network（前馈网络）— 图中绿色框**
🧠 注意力让词和词之间互相交流后，每个词再单独"消化"一下。

它是两层简单的全连接网络（就是神经元那张图里的结构！）。
每个词独立地做一次非线性变换——类似于：小组讨论完之后，每个同学自己再想一想、总结一下。

**7. Add & Norm — 图中灰色小条 + 右侧虚线**
这是一个"保险机制"，每一层都有：

- **Add（残差连接）**：把这一层的"原始输入"直接加到"处理后的输出"上。
  类比：抄作业时，不管你改了什么，都把原文也保留一份。
  作用：防止信息在层层传递中丢失。图中右侧的虚线就是这条"捷径"。

- **Norm（层归一化）**：把数据"拉回正常范围"，不让数字变得太大或太小。
  类比：考试阅卷时统一评分标准，避免分数飘忽不定。

**8. Linear + Softmax（输出层）— 图中底部紫色框**
📊 最后一步：选词输出。

- **Linear**：把 Decoder 的输出映射到整个词表（比如 3 万个词）。每个词得到一个分数。
- **Softmax**：把分数转成概率（所有概率加起来 = 100%）。分数最高的词就是预测结果。

图中底部的彩色柱状就是概率分布——柱子越高，这个词被选中的概率越大。

| | Encoder（编码器） | Decoder（解码器） |
|---|---|---|
| 类比 | 读题、理解题意 | 写答案 |
| 注意力方向 | **双向**（每个词能看到所有词） | **单向**（只能看到前面的词） |
| 目标 | 理解输入的完整语义 | 一个一个地生成输出 |
| 代表模型 | BERT | GPT、Claude、LLaMA |

### 🚀 为什么 GPT/Claude 等 LLM 只用 Decoder（解码器）？

- **Encoder 像「学霸做阅读理解」** — 能前后看，全面理解，但只能回答选择题/填空题（理解类任务）
- **Decoder 像「即兴演讲者」** — 只能往前说，说到哪算哪，但能无限发挥、自由生成

为什么选 Decoder？因为我们需要 AI **生成**新内容（写代码、写文章、对话），而不仅仅是理解已有文本。

**三个关键原因：**
1. **生成任务的本质** — 写作就是"一个字接一个字往下写"，天然是单向的，跟 Decoder 的工作方式完全一致
2. **更容易扩大规模** — Decoder-only 结构更简单，更容易堆叠到数千亿参数
3. **大力出奇迹** — 研究发现，当数据和参数足够多时，Decoder 也能学会"理解"（虽然它只能往前看，但它已经读过海量文本，早就"理解"了）

### 📚 BERT 和 Transformer 的关系

**BERT 完全基于 Transformer！** 只不过它只用了 Encoder（左半部分）。

你可以这样记：
- **BERT = Transformer 的「阅读理解」部分** — 擅长理解，能做分类、判断、提取信息
- **GPT = Transformer 的「写作文」部分** — 擅长生成，能写文章、写代码、聊天

BERT 的特色是「完形填空式训练」：随机挖掉句子里 15% 的词，让模型猜被挖掉的词是什么。因为可以前后看，所以猜词很准，理解力强——但因为训练方式不是"往下写"，所以不擅长生成连贯的长文本。

-->

<div v-click="3">

3. **[Transformer 架构](https://arxiv.org/abs/1706.03762)** 通过**注意力机制**让每个词"关注"其他词，从而理解语义
   - **Positional Encoding** 给每个词贴上"座位号"，让模型知道词的顺序
   - **Encoder** 「读题」— 双向阅读全文，理解输入的完整含义
   - **Decoder** 「写答案」— 逐字生成输出（GPT/Claude 只用这部分）

</div>

<LLMConcepts :activeCount="$clicks" />


---
layout: vibe-step
activeStep: action
---

# 04. Take Action: 执行行动

### 核心能力：**工具调用 (Tool Use / Function Calling)**

这是 Vibe Coding 从“说”到“做”的关键跨越。

| 工具 | 对应操作 | 意义 |
|:---|:---|:---|
| **WriteFile** | 直接修改磁盘上的代码 | 无需开发者进行复制粘贴 |
| **Terminal** | 运行 `npm install` 或 `git commit` | 掌控开发环境的执行权 |
| **LSP** | 请求 IDE 获得语法提示 | 获取精准的代码元数据 |

---
layout: vibe-step
activeStep: verify
---

# 05. Verify & Feedback: 自动验证与循环

### 核心概念：**Agentic Loop (闭环)**

**Agent 不会写完就跑。**

1. **自动验证 (Verify)**：代码写入后，Agent 自动调用 `Linter` 或检查编译错误。
2. **错误回流 (Feedback Loop)**：如果报错，报错信息作为**新 Context**，自动触发下一轮推理。
3. **自我修复**：
   - AI: “哦，我刚才漏掉了一个 Import。”
   - AI: “自动重试，修正代码。”

---
layout: vibe-step
activeStep: steer
---

# 06. Human In The Loop: 人机协作

### 核心理念：**打断与转向 (Steer)**

AI 的预测不是 100% 准确的。Vibe Coding 强调的是**人类的实时感官与导航**：

- **及早打断**：发现 AI 推理偏离（例如用了错误的组件库），点击 **Interrupt**。
- **重定向**：注入新的约束条件 —— “不用这个库，改用原生 CSS 实现”。
- **最终把关**：AI 完成后，开发者仅需对增量（Diff）进行最后的 Code Review。

---
layout: vibe-step
activeStep: done
---

# 总结：理解原理，驾驭 Vibe

<div class="grid grid-cols-2 gap-4">

<div class="border border-blue-500/30 p-4 bg-blue-500/5">

### 从“打字员”转向“审稿人”
你不再关注分号和括号，而是关注**逻辑边界**和**架构意图**。

</div>

<div class="border border-purple-500/30 p-4 bg-purple-500/5">

### 把 AI 当成“高级外包”
给它清晰的 Context（语境），给它趁手的 Tools（工具），并做好 Verify（审核）。

</div>

</div>

<div class="text-center mt-8">

## Vibe Coding 不是魔法，而是**感知-思考-行动**的自动化循环。

</div>
