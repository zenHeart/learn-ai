# Prompt Framework
<!--
Other framework structures
https://learningprompt.wiki/docs/chatGPT/tutorial-extras/ChatGPT%20Prompt%20Framework#crispe-prompt-framework
 -->
|Component|Function|Required
|---|---|---|
**Instruction**|Specific task you want the model to perform| Required
**Context**|Additional information to guide the language model's response| Optional
**Input Data**|Content the model needs to process|Optional
**Output Indicator**|Type or format the model should output| Optional

<!--
* [CRISPE](https://github.com/mattnigh/ChatGPT3-Free-Prompt-List) prompt
* [langpt](https://github.com/yzfly/LangGPT)
-->

---

<!-- Typical prompt patterns -->

# Zero-Shot Prompting
Contains only instructions

---

# Few-Shot Prompting
<!-- Paper https://arxiv.org/abs/2102.09690 -->

Contains instructions, example inputs and outputs to help the model learn response patterns
**Ensure quality of input examples to avoid garbage in, garbage out**

---

# Chain-of-Thought Prompting (COT Pattern)
Assist the model in completing tasks through a series of reasoning prompts

<v-clicks>

* Use **"Let's solve this problem step by step to ensure we get the right answer"**

</v-clicks>

<!-- # Other Concepts
* [Self-Consistency] -->

---

# Mixed Models
* Zero-shot with COT
* Few-shot with COT
...

----

# Core Principles

<v-clicks>

* Be Precise and Clear, clearly define your requirements
  * Add examples
  * Break down tasks
  * Add guide words (code generation)
  * To Do And Not To Do (tell AI what to do)
  * Add task or role (chat-type tasks)
  * Use symbols to separate content
  * Adjust output through format words (formatting)
* Verify Carefully, be patient
    <!-- Errors in mathematical operations -->
  * Results may be incorrect, don't rely entirely on the model
  * Obtain best answers through iterative prompt adjustments
* [OpenAI Prompt Best Practice](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api)

</v-clicks>

