# 3. Context Engineering

## 什么是 Context Engineering (上下文工程)？

> **上下文工程** 是指在与大模型交互时，对输入信息进行**结构化、裁剪、召回和排序**的系统性实践。

<v-clicks>

* **不仅是堆砌，是裁剪**: 喂给模型的信息并非越多越好（“大海捞针”会引发幻觉和遗忘）。
* **突破物理限制**: 让模型具备访问私有代码库、实时 API 数据的能力。
* **工程学本质**: 核心是如何在有限的 Token 预算和注意力机制下，提供**最高信噪比 (Signal-to-Noise Ratio)** 的信息。

</v-clicks>

---
layout: two-cols-header
---

# 溯源：Context 技术的演进脉络

> 从“暴力拼接”到“结构化工程” (参考顶级智能体 Manus 的经验)

::left::

<div class="mt-4">

**阶段一：暴力拼接时代 (2022)**
- **拼接大法**：把所有的对话历史、文档内容一股脑全塞进 Prompt。
- **痛点**：轻易爆显存（Token 溢出），首尾效应明显（Lost in the Middle）。

**阶段二：向量检索时代 (2023)**
- **基础 RAG**：将文档切块（Chunk），转换为向量（Embeddings），基于余弦相似度召回。
- **痛点**：语义相似不代表逻辑相关，检索准确率遇到瓶颈。

</div>

::right::

<div class="mt-4">

**阶段三：结构化 Context 时代 (2024-2026)**
- **图与树的结合**：引入知识图谱（GraphRAG）和混合检索。
- **动态修剪 (Trimming)**：根据任务当前状态，动态丢弃不相关的历史，保持上下文极其纯净。
- **[Manus 的核心洞察](https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus)**：最好的上下文不是“给得够多”，而是“只给当前步最需要的”。

</div>

---
layout: two-cols-header
---

# 强对比：为什么不能无脑塞代码？

> 庞大无序的 Context 反而是毒药，会极大地拉低大模型的智商。

::left::

### ❌ 无脑塞积木 (大海捞针)

```markdown
请帮我修复页面点击按钮不弹窗的 Bug。
下面是整个 src 目录所有文件的代码：

[此处粘贴了 50 个文件，共 80,000 个 Token]
...
```

<div class="text-sm mt-4 text-red-500 bg-red-50 p-4 rounded-lg">
<strong>结果：</strong><br/>
耗时极长 (约 20-30 秒)，模型被大量无关文件(如 utils, css)分散注意力，最终瞎编了一个修复方案，完全没有定位到真实的逻辑漏洞。
</div>

::right::

### ✅ 精心裁剪的 Context (高信噪比)

```markdown
请帮我修复点击按钮不弹窗的 Bug。

【报错日志】
Uncaught TypeError: Cannot read properties of undefined (reading 'show') at Button.tsx:45

【相关文件 1: Button.tsx】
// ...仅提供组件内 click handler 逻辑...

【相关文件 2: ModalStore.ts】
// ...仅提供状态定义...
```

<div class="text-sm mt-4 text-green-600 bg-green-50 p-4 rounded-lg">
<strong>结果：</strong><br/>
耗时 3 秒，由于没有杂音干扰，模型瞬间锁定 `ModalStore` 未初始化的根因并给出准确修复。
</div>

---

# RAG（检索增强生成）: 跨越信息孤岛

## 核心概念

> RAG = Retrieval（检索）+ Augmented（增强）+ Generation（生成）

<v-clicks>

1. **知识库准备 (Indexing)**: 将企业内部的 Wiki、PRD、API 文档切块并向量化存储。
2. **检索 (Retrieval)**: 当用户提问时，从向量数据库中快速找到 Top-K 个最相关的片段。
3. **生成 (Generation)**: 把这几个片段作为 Context 喂给 LLM，让它“开卷考试”。

</v-clicks>

---

# 场景：利用 RAG 构建企业内部问答

使用最权威的框架 [LlamaIndex](https://docs.llamaindex.ai/) 几行代码搞定知识外挂。

```python
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader

# 1. 读取本地目录（如你的公司前端规范 Markdown 文件）
documents = SimpleDirectoryReader("./company-frontend-guidelines").load_data()

# 2. 建立向量索引 (自动调用 Embedding 模型)
index = VectorStoreIndex.from_documents(documents)

# 3. 构建查询引擎
query_engine = index.as_query_engine()

# 4. 生成答案，LLM 会基于找到的内部规范来回答
response = query_engine.query("根据公司规范，React 组件应该如何命名？")
print(response)
```

---

# Context 记忆机制的工程落地

如何让模型”记住”之前的多轮对话而不把 Token 撑爆？

<v-clicks>

## 1. 消息修剪 (Message Trimming)
- **策略**: 只保留 System Prompt 和最近的 N 轮对话，丢弃中间的废话。
- **目的**: 永远把 Token 控制在安全线以下，避免幻觉。

## 2. 摘要压缩 (Summarization)
- **策略**: 当对话超过 1 万 Token 时，调用一个廉价的小模型（如 Haiku/GPT-4o-mini）对前文进行总结。
- **替换**: 用一段 200 字的摘要替换掉原来 10000 字的聊天记录，继续对话。

## 3. 语义缓存 (Prompt Caching)
- **最佳实践**: 像 Anthropic / Cursor 支持将巨大的 Context（如几百万字的项目代码）缓存起来。相同的 Context 再次请求时，**成本降低 90%，响应速度提升 10 倍**。

</v-clicks>

---

# ⚡ Manus 生产级 Context 优化经验

> 来自全球最强 AI Agent [Manus](https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus) 团队的实战总结。

## 经验 1：KV-Cache 命中率是最重要的指标

### 问题
输入/输出 Token 比例经常是 100:1（用户一句话，Context 几万 Token）。

### 方案
提升 KV-Cache 命中率，直接影响延迟和成本。

### 做法

| 做法 | 说明 |
|------|------|
| 保持提示词前缀稳定 | 不要每次请求都修改前缀 |
| 保持上下文仅追加 | 只新增，不要删除后重新添加 |
| 使用确定性序列化 | 相同数据结构用相同的序列化格式 |

---

## 经验 2：Mask 而非 Remove

### 问题
在迭代中动态增删工具（Tool）会破坏 KV-Cache，导致缓存失效。

### 方案
使用状态机管理工具可用性，而不是直接增删。

### 做法

| ❌ 错误做法 | ✅ 正确做法 |
|------------|------------|
| 每次请求动态增删 tools 数组 | 使用 mask token logits 约束行动空间 |
| 根据任务随时开关工具 | 预先定义所有可用工具，通过状态机控制是否启用 |

---

## 经验 3：通过”背诵”操纵注意力

### 问题
长上下文存在”中间丢失”（Lost in the Middle）效应——中间的信息容易被遗忘。

### 方案
将目标”背诵”到上下文末尾，持续更新。

### 做法

| 做法 | 说明 |
|------|------|
| 持续更新 todo.md | 将当前任务目标写在文件末尾 |
| 关键信息置顶 | 把最重要的信息放在 Context 开头和结尾 |
| 避免精确时间戳 | 精确到秒的时间戳会破坏缓存命中率 |

---

## 经验 4：保留错误信息

### 问题
Agent 执行动作失败后，错误信息被丢弃，导致重复犯错。

### 方案
让模型看到失败的动作和观察结果。

### 做法

| 做法 | 说明 |
|------|------|
| 保留错误日志 | 让模型看到失败的具体原因 |
| 调整内部信念 | 模型可以根据错误信息调整判断 |
| 避免重复犯错 | 模型会记住”这个方法不行” |

---

## 经验 5：避免 Few-Shot 陷阱

### 问题
过多相似的行动-观察对会导致模型陷入惯性，不会变通。

### 方案
在动作和观察中引入结构化多样性。

### 做法

| ❌ 错误做法 | ✅ 正确做法 |
|------------|------------|
| 连续多个相似的 Tool Call 示例 | 在示例中混合不同类型的工具 |
| 固定的观察-行动模式 | 让模型学会根据不同情况选择不同工具 |

---
layout: center
---
# 本章小结：Context 工程

<v-clicks>

1. **核心心法**: 上下文的质量（信噪比）远比数量更重要，做减法比做加法更难。
2. **RAG 架构**: "检索 + 增强生成" 是解决企业私有数据接入的工业级标配方案。
3. **工程优化**: 结合消息修剪、摘要压缩与 Prompt Caching，用最少的 Token 办最大的事。
4. **Manus 经验**: KV-Cache 命中率、Mask 而非 Remove、"背诵"操纵注意力、保留错误信息。

</v-clicks>
