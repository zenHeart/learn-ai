# PEFT (参数高效微调)

## 什么是 PEFT？

**参数高效微调 (Parameter-Efficient Fine-Tuning, PEFT)** 是一组技术，用于在不重新训练所有参数的情况下微调大语言模型 (LLM)。PEFT 不是更新数十亿个权重，而是仅更新一小部分（通常 < 1%）添加的参数。

**核心思想**: 冻结大规模预训练模型，仅训练小的适配器层 (adapter layers)。

**好处**:
- **更低的硬件成本**: 可以在消费级 GPU 上运行（例如，单个 RTX 4090 而不是 A100 集群）。
- **存储效率**: "适配器" 是小文件 (MBs) vs 完整模型 (GBs)。
- **多租户**: 你可以服务一个基础模型，并即时为不同的用户/任务交换小的适配器。

## LoRA (低秩适应)

**LoRA (Low-Rank Adaptation)** 是最流行的 PEFT 技术。

- **工作原理**: 它将小的“低秩分解矩阵”注入模型中，并仅训练这些矩阵。
- **类比**: 想象编辑一本书。不是重写整本书（全量微调），你只是在便利贴上写下你的编辑，并将它们贴在页面上（LoRA）。阅读时，你阅读原始页面 + 便利贴。

## 公司何时使用 PEFT

1. **具有成本效益的定制**: 当他们需要针对特定任务（例如，“SQL 生成器”）的自定义模型，但无法承担训练完整 70B 参数模型的费用时。
2. **隐私/本地部署**: 在本地硬件上运行微调过的开源模型（Llama 3, Mistral）。
3. **个性化 AI**: 创建数千个特定于用户的模型（例如，每个用户一个风格适配器），共享同一个基础模型。

::: tip 前端相关性
**运行本地 LLM**

如果你使用 **Ollama** 或 **LM Studio** 等工具，你通常是在下载“量化”模型或应用 LoRA 适配器。了解 PEFT 有助于你理解为什么你可以在 MacBook 上运行强大的 AI。
:::

## 延伸阅读

- [LoRA: Low-Rank Adaptation of Large Language Models (Paper)](https://arxiv.org/abs/2106.09685)
- [Hugging Face PEFT Library](https://github.com/huggingface/peft)