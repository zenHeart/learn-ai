import{_ as e}from"./chunks/plugin-vue_export-helper.DlAUqK2U.js";import{c as l,o as n,ad as r}from"./chunks/mermaid.Cb40Nz1P.js";import"./chunks/cytoscape.C2CwDKBM.js";import"./chunks/dayjs.C32PoDnw.js";const u=JSON.parse('{"title":"前端机器学习库","description":"","frontmatter":{},"headers":[],"relativePath":"zh/integration/frontend-ml/index.md","filePath":"zh/integration/frontend-ml/index.md"}'),s={name:"zh/integration/frontend-ml/index.md"};function a(o,t,i,d,g,f){return n(),l("div",null,[...t[0]||(t[0]=[r('<h1 id="前端机器学习库" tabindex="-1">前端机器学习库 <a class="header-anchor" href="#前端机器学习库" aria-label="Permalink to &quot;前端机器学习库&quot;">​</a></h1><p>在浏览器中运行 ML 正在成为标准。这里是主要玩家。</p><table tabindex="0"><thead><tr><th style="text-align:left;">库</th><th style="text-align:left;">最适合</th><th style="text-align:left;">大小</th><th style="text-align:left;">复杂度</th></tr></thead><tbody><tr><td style="text-align:left;"><strong>Transformers.js</strong></td><td style="text-align:left;">NLP, LLMs, 音频</td><td style="text-align:left;">中</td><td style="text-align:left;">低 (易于使用的 API)</td></tr><tr><td style="text-align:left;"><strong>TensorFlow.js</strong></td><td style="text-align:left;">训练, 自定义模型</td><td style="text-align:left;">大</td><td style="text-align:left;">高</td></tr><tr><td style="text-align:left;"><strong>ONNX Runtime Web</strong></td><td style="text-align:left;">生产环境, 优化</td><td style="text-align:left;">小</td><td style="text-align:left;">中</td></tr><tr><td style="text-align:left;"><strong>MediaPipe</strong></td><td style="text-align:left;">视觉, 姿态, 人脸</td><td style="text-align:left;">小</td><td style="text-align:left;">低</td></tr></tbody></table><h2 id="决策矩阵" tabindex="-1">决策矩阵 <a class="header-anchor" href="#决策矩阵" aria-label="Permalink to &quot;决策矩阵&quot;">​</a></h2><ul><li><strong>需要运行 HuggingFace 模型？</strong> -&gt; 使用 <strong>Transformers.js</strong>。</li><li><strong>需要在浏览器中训练模型？</strong> -&gt; 使用 <strong>TensorFlow.js</strong>。</li><li><strong>需要特定的计算机视觉（手部追踪）？</strong> -&gt; 使用 <strong>MediaPipe</strong>。</li><li><strong>需要自定义模型的最大速度？</strong> -&gt; 使用 <strong>ONNX Runtime + WebGPU</strong>。</li></ul><h2 id="性能-webgpu-vs-wasm" tabindex="-1">性能 (WebGPU vs WASM) <a class="header-anchor" href="#性能-webgpu-vs-wasm" aria-label="Permalink to &quot;性能 (WebGPU vs WASM)&quot;">​</a></h2><p>现代库使用 <strong>WebAssembly (WASM)</strong> 进行 CPU 执行，使用 <strong>WebGPU</strong> 进行 GPU 执行。 WebGPU 在大型矩阵乘法（如 LLM）方面快 10-100 倍。</p><h2 id="下一步" tabindex="-1">下一步 <a class="header-anchor" href="#下一步" aria-label="Permalink to &quot;下一步&quot;">​</a></h2><ul><li><strong><a href="./transformersjs.html">Transformers.js 指南</a></strong> (推荐入门)</li><li><strong><a href="./tensorflowjs.html">TensorFlow.js 指南</a></strong></li><li><strong><a href="./onnx-runtime.html">ONNX 指南</a></strong></li></ul>',9)])])}const y=e(s,[["render",a]]);export{u as __pageData,y as default};
