import{_ as s}from"./chunks/plugin-vue_export-helper.DlAUqK2U.js";import{c as i,o as l,ad as n}from"./chunks/mermaid.Cb40Nz1P.js";import"./chunks/cytoscape.C2CwDKBM.js";import"./chunks/dayjs.C32PoDnw.js";const F=JSON.parse('{"title":"Ollama","description":"","frontmatter":{},"headers":[],"relativePath":"zh/products/tools/ollama.md","filePath":"zh/products/tools/ollama.md"}'),e={name:"zh/products/tools/ollama.md"};function t(p,a,h,r,k,o){return l(),i("div",null,[...a[0]||(a[0]=[n(`<h1 id="ollama" tabindex="-1">Ollama <a class="header-anchor" href="#ollama" aria-label="Permalink to &quot;Ollama&quot;">​</a></h1><h2 id="简介" tabindex="-1">简介 <a class="header-anchor" href="#简介" aria-label="Permalink to &quot;简介&quot;">​</a></h2><p><a href="https://github.com/ollama/ollama" target="_blank" rel="noreferrer">Ollama</a> 类似于包管理器（类比于 <code>pip</code>、<code>brew</code> 等），降低了模型下载、安装、使用和管理的成本。</p><h2 id="安装" tabindex="-1">安装 <a class="header-anchor" href="#安装" aria-label="Permalink to &quot;安装&quot;">​</a></h2><ol><li>官网下载客户端：<a href="https://ollama.com/download" target="_blank" rel="noreferrer">ollama</a></li><li>客户端下载成功后，安装命令行工具 <code>ollama</code></li><li>在终端安装模型，例如 <code>ollama run deepseek-r1:8b</code></li><li>模型下载成功后，直接输入文本回车和模型交互，具体终端使用详见<a href="#命令行交互">命令行交互</a></li></ol><h2 id="常用命令" tabindex="-1">常用命令 <a class="header-anchor" href="#常用命令" aria-label="Permalink to &quot;常用命令&quot;">​</a></h2><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 查看帮助</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ollama</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> help</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 列出本地模型</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ollama</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> list</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 运行某个模型</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ollama</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> run</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> deepseek-r1:8b</span></span></code></pre></div><h2 id="命令行交互" tabindex="-1">命令行交互 <a class="header-anchor" href="#命令行交互" aria-label="Permalink to &quot;命令行交互&quot;">​</a></h2><p>本地模型运行后可以直接输入文本，回车后模型会给出回答。除此之外常用默认指令有：</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">/help</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 帮助</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">/bye</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 退出</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">/clear</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 清除</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">/exit</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 退出</span></span></code></pre></div><h2 id="创建自定义模型" tabindex="-1">创建自定义模型 <a class="header-anchor" href="#创建自定义模型" aria-label="Permalink to &quot;创建自定义模型&quot;">​</a></h2><ol><li>新建 <code>Modelfile</code> 文件</li></ol><div class="language-dockerfile vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">dockerfile</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 继承 deepseek-r1:8b 模型</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">FROM</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> deepseek-r1:8b</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 设置温度参数 </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">PARAMETER temperature 0.8</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 设置上下文长度</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">PARAMETER num_ctx 4096</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 自定义 prompt</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 设置自定义系统消息以指定聊天助手的行为</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">SYSTEM You are Mario from super mario bros, acting as an assistant.</span></span></code></pre></div><ol start="2"><li>创建模型</li></ol><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 项目根目录执行</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ollama</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> create</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> teaching</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 创建成功后，会生成一个 teaching 模型, 查找模型 name</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ollama</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> list</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 运行自定义模型，假设模型名称为 mymodel:latest</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ollama</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> run</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> mymodel:latest</span></span></code></pre></div><h2 id="参考资料" tabindex="-1">参考资料 <a class="header-anchor" href="#参考资料" aria-label="Permalink to &quot;参考资料&quot;">​</a></h2><ul><li><a href="https://datawhalechina.github.io/handy-ollama/#/C1/1.%20Ollama%20%E4%BB%8B%E7%BB%8D" target="_blank" rel="noreferrer">Ollama 介绍</a></li></ul>`,17)])])}const u=s(e,[["render",t]]);export{F as __pageData,u as default};
