import{_ as t}from"./chunks/plugin-vue_export-helper.DlAUqK2U.js";import{c as n,o as i,ad as r}from"./chunks/mermaid.Cb40Nz1P.js";import"./chunks/cytoscape.C2CwDKBM.js";import"./chunks/dayjs.C32PoDnw.js";const f=JSON.parse('{"title":"SFT (Supervised Fine-Tuning)","description":"","frontmatter":{},"headers":[],"relativePath":"tech/training/SFT.md","filePath":"tech/training/SFT.md"}'),a={name:"tech/training/SFT.md"};function s(o,e,l,d,u,g){return i(),n("div",null,[...e[0]||(e[0]=[r('<h1 id="sft-supervised-fine-tuning" tabindex="-1">SFT (Supervised Fine-Tuning) <a class="header-anchor" href="#sft-supervised-fine-tuning" aria-label="Permalink to &quot;SFT (Supervised Fine-Tuning)&quot;">​</a></h1><h2 id="what-is-fine-tuning" tabindex="-1">What is Fine-Tuning? <a class="header-anchor" href="#what-is-fine-tuning" aria-label="Permalink to &quot;What is Fine-Tuning?&quot;">​</a></h2><p><strong>Supervised Fine-Tuning (SFT)</strong> is the process of training an existing pre-trained model on your specific data to adapt it to your domain or task. It adjusts the model&#39;s parameters to specialize in your use case.</p><p><strong>The Core Idea</strong>: Take a general-purpose LLM → Train it on your data → Get a specialized model</p><p><strong>Why Fine-Tuning</strong>:</p><ul><li>Improve performance on domain-specific tasks</li><li>Learn specialized terminology and patterns</li><li>Reduce prompt engineering needs</li><li>Better consistency in outputs</li></ul><div class="info custom-block"><p class="custom-block-title">Frontend Engineer Recommendation</p><p><strong>For Implementation: Hire ML Engineers</strong></p><p>As a frontend developer, you generally should <strong>not</strong> be implementing SFT yourself unless using a managed service like OpenAI&#39;s fine-tuning API. This is typically the domain of Machine Learning Engineers.</p></div><h2 id="sft-vs-rag-vs-prompt-engineering" tabindex="-1">SFT vs RAG vs Prompt Engineering <a class="header-anchor" href="#sft-vs-rag-vs-prompt-engineering" aria-label="Permalink to &quot;SFT vs RAG vs Prompt Engineering&quot;">​</a></h2><table tabindex="0"><thead><tr><th>Aspect</th><th>Prompt Engineering</th><th>RAG</th><th>Fine-Tuning (SFT)</th></tr></thead><tbody><tr><td><strong>Cost</strong></td><td>Very Low (free)</td><td>Low (inference + retrieval)</td><td>Very High (GPU training)</td></tr><tr><td><strong>Setup Time</strong></td><td>Minutes</td><td>Hours to days</td><td>Days to weeks</td></tr><tr><td><strong>Data Needed</strong></td><td>None (just prompts)</td><td>Documents for retrieval</td><td>100s-1000s labeled examples</td></tr><tr><td><strong>Speed</strong></td><td>Fast</td><td>Medium (retrieval overhead)</td><td>Fast (after training)</td></tr><tr><td><strong>Updates</strong></td><td>Instant</td><td>Instant (update knowledge base)</td><td>Requires retraining</td></tr><tr><td><strong>Best For</strong></td><td>General tasks</td><td>Dynamic knowledge</td><td>Specialized domains</td></tr></tbody></table><h2 id="when-to-use-fine-tuning" tabindex="-1">When to Use Fine-Tuning <a class="header-anchor" href="#when-to-use-fine-tuning" aria-label="Permalink to &quot;When to Use Fine-Tuning&quot;">​</a></h2><h3 id="✅-good-use-cases" tabindex="-1">✅ Good Use Cases <a class="header-anchor" href="#✅-good-use-cases" aria-label="Permalink to &quot;✅ Good Use Cases&quot;">​</a></h3><ol><li><p><strong>Specialized Domain Language</strong></p><ul><li>Medical diagnosis (medical terminology)</li><li>Legal document analysis (legal jargon)</li></ul></li><li><p><strong>Consistent Output Format</strong></p><ul><li>Always need specific JSON structure</li><li>Code generation in proprietary framework</li></ul></li><li><p><strong>Style and Tone</strong></p><ul><li>Brand-specific writing style</li><li>consistent personality across responses</li></ul></li><li><p><strong>Performance Optimization</strong></p><ul><li>Need smaller model with specialized capability to reduce costs/latency</li></ul></li></ol><h3 id="❌-bad-use-cases-use-rag-instead" tabindex="-1">❌ Bad Use Cases (Use RAG Instead) <a class="header-anchor" href="#❌-bad-use-cases-use-rag-instead" aria-label="Permalink to &quot;❌ Bad Use Cases (Use RAG Instead)&quot;">​</a></h3><ol><li><p><strong>Frequently Changing Information</strong></p><ul><li>Product catalogs</li><li>News and updates</li></ul></li><li><p><strong>Large Knowledge Bases</strong></p><ul><li>Company wikis</li><li>Technical manuals</li></ul></li><li><p><strong>Limited Budget</strong></p><ul><li>Startups without GPU access</li><li>Prototype/MVP stage</li></ul></li></ol><h2 id="services-for-fine-tuning" tabindex="-1">Services for Fine-Tuning <a class="header-anchor" href="#services-for-fine-tuning" aria-label="Permalink to &quot;Services for Fine-Tuning&quot;">​</a></h2><p>If you decide SFT is necessary, these platforms offer managed fine-tuning services that don&#39;t require managing GPU infrastructure:</p><ul><li><a href="https://platform.openai.com/docs/guides/fine-tuning" target="_blank" rel="noreferrer">OpenAI Fine-Tuning</a> (GPT-3.5, GPT-4)</li><li><a href="https://docs.anthropic.com/en/docs/build-with-claude/fine-tuning-overview" target="_blank" rel="noreferrer">Anthropic Fine-Tuning</a> (Claude Haiku)</li><li><a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning" target="_blank" rel="noreferrer">Azure OpenAI Service</a></li><li><a href="https://www.together.ai/" target="_blank" rel="noreferrer">Together AI</a> (Open source models)</li><li><a href="https://www.anyscale.com/" target="_blank" rel="noreferrer">Anyscale</a> (Open source models)</li></ul><h2 id="next-steps" tabindex="-1">Next Steps <a class="header-anchor" href="#next-steps" aria-label="Permalink to &quot;Next Steps&quot;">​</a></h2><ul><li><strong>Evaluate if you really need SFT</strong> (try RAG first)</li><li><strong>Start with OpenAI&#39;s fine-tuning API</strong> if you must proceed</li><li><strong>Collaborate with ML Engineers</strong> for complex model training</li></ul>',19)])])}const T=t(a,[["render",s]]);export{f as __pageData,T as default};
