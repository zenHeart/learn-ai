import{_ as i}from"./chunks/plugin-vue_export-helper.DlAUqK2U.js";import{c as a,o as t,ad as n}from"./chunks/mermaid.Cb40Nz1P.js";import"./chunks/cytoscape.C2CwDKBM.js";import"./chunks/dayjs.C32PoDnw.js";const u=JSON.parse('{"title":"AI 缓存策略","description":"","frontmatter":{},"headers":[],"relativePath":"zh/deployment/caching.md","filePath":"zh/deployment/caching.md"}'),e={name:"zh/deployment/caching.md"};function l(h,s,p,r,o,k){return t(),a("div",null,[...s[0]||(s[0]=[n(`<h1 id="ai-缓存策略" tabindex="-1">AI 缓存策略 <a class="header-anchor" href="#ai-缓存策略" aria-label="Permalink to &quot;AI 缓存策略&quot;">​</a></h1><p>LLM 请求<strong>慢</strong>且<strong>贵</strong>。缓存是解决这两点的最佳方案。</p><h2 id="_1-标准-api-缓存-vercel-data-cache" tabindex="-1">1. 标准 API 缓存 (Vercel Data Cache) <a class="header-anchor" href="#_1-标准-api-缓存-vercel-data-cache" aria-label="Permalink to &quot;1. 标准 API 缓存 (Vercel Data Cache)&quot;">​</a></h2><p>如果提示词是静态的（例如，“生成每日星座运势”），缓存响应。</p><div class="language-typescript vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">typescript</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// Next.js App Router</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> revalidate</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 3600</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// 缓存 1 小时</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> async</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> function</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> GET</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">() {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> completion</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> await</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> openai.chat.completions.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">create</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">({ </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> });</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Response.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">json</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(completion);</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><h2 id="_2-语义缓存-圣杯" tabindex="-1">2. 语义缓存 (圣杯) <a class="header-anchor" href="#_2-语义缓存-圣杯" aria-label="Permalink to &quot;2. 语义缓存 (圣杯)&quot;">​</a></h2><p>用户很少输入完全相同的内容。</p><ul><li>用户 A: &quot;Who is Elon Musk?&quot;</li><li>用户 B: &quot;Tell me about Elon Musk&quot;</li></ul><p>标准缓存未命中。<strong>语义缓存</strong>命中。</p><p><strong>工作原理</strong>:</p><ol><li>嵌入传入的提示词。</li><li>在向量数据库 (Redis/Pinecone) 中搜索相似的历史提示词 (阈值 &gt; 0.95)。</li><li>如果找到，返回存储的答案。</li></ol><p><strong>库</strong>:</p><ul><li><strong>GPTCache</strong>: Python 库。</li><li><strong>Upstash Semantic Cache</strong>: Serverless 解决方案。</li></ul><h2 id="_3-边缘缓存-cdn" tabindex="-1">3. 边缘缓存 (CDN) <a class="header-anchor" href="#_3-边缘缓存-cdn" aria-label="Permalink to &quot;3. 边缘缓存 (CDN)&quot;">​</a></h2><p>对于 AI 生成的资产（图像、音频），始终在边缘 (CDN) 缓存它们。 不要从数据库提供生成的图像；将它们上传到 S3/R2 并通过 Cloudflare/Vercel Edge 提供。</p><h2 id="缓存失效" tabindex="-1">缓存失效 <a class="header-anchor" href="#缓存失效" aria-label="Permalink to &quot;缓存失效&quot;">​</a></h2><p>AI 模型会变化（OpenAI 的更新）。</p><ul><li><strong>基于时间</strong>: 每周过期一次缓存。</li><li><strong>基于模型</strong>: 当你从 <code>gpt-3.5</code> 升级到 <code>gpt-4o</code> 时，使所有缓存失效。</li></ul>`,18)])])}const y=i(e,[["render",l]]);export{u as __pageData,y as default};
