import{_ as i}from"./chunks/plugin-vue_export-helper.DlAUqK2U.js";import{c as a,o as n,ad as e}from"./chunks/mermaid.Cb40Nz1P.js";import"./chunks/cytoscape.C2CwDKBM.js";import"./chunks/dayjs.C32PoDnw.js";const y=JSON.parse('{"title":"Hugging Face 集成","description":"","frontmatter":{},"headers":[],"relativePath":"zh/integration/apis/huggingface.md","filePath":"zh/integration/apis/huggingface.md"}'),t={name:"zh/integration/apis/huggingface.md"};function l(h,s,p,k,r,g){return n(),a("div",null,[...s[0]||(s[0]=[e(`<h1 id="hugging-face-集成" tabindex="-1">Hugging Face 集成 <a class="header-anchor" href="#hugging-face-集成" aria-label="Permalink to &quot;Hugging Face 集成&quot;">​</a></h1><p>Hugging Face 是 &quot;AI 界的 GitHub&quot;，托管着超过 50 万个开源模型。你可以通过其 <strong>Serverless Inference API</strong> 运行这些模型，或者在浏览器中本地运行。</p><h2 id="serverless-inference-api" tabindex="-1">Serverless Inference API <a class="header-anchor" href="#serverless-inference-api" aria-label="Permalink to &quot;Serverless Inference API&quot;">​</a></h2><p>使用开源模型（如 Llama 3, Mistral, Bert）而不管理服务器的最简单方法。</p><h3 id="设置" tabindex="-1">设置 <a class="header-anchor" href="#设置" aria-label="Permalink to &quot;设置&quot;">​</a></h3><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">npm</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> @huggingface/inference</span></span></code></pre></div><p>从 <a href="https://huggingface.co/settings/tokens" target="_blank" rel="noreferrer">Hugging Face 设置</a> 获取 token。</p><h3 id="文本生成-llama-3" tabindex="-1">文本生成 (Llama 3) <a class="header-anchor" href="#文本生成-llama-3" aria-label="Permalink to &quot;文本生成 (Llama 3)&quot;">​</a></h3><div class="language-typescript vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">typescript</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> { HfInference } </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;@huggingface/inference&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> hf</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> new</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> HfInference</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(process.env.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">HF_TOKEN</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">);</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">async</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> function</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> main</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">() {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> stream</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> hf.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">textGenerationStream</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">({</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    model: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;meta-llama/Meta-Llama-3-8B-Instruct&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    inputs: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Explain why the sky is blue.&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    parameters: {</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">      max_new_tokens: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">200</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">      temperature: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.7</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    },</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  });</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  for</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> await</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> chunk</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> of</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> stream) {</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    process.stdout.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">write</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(chunk.token.text);</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><h3 id="embeddings-特征提取" tabindex="-1">Embeddings (特征提取) <a class="header-anchor" href="#embeddings-特征提取" aria-label="Permalink to &quot;Embeddings (特征提取)&quot;">​</a></h3><p>生成用于语义搜索的向量嵌入。</p><div class="language-typescript vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">typescript</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> output</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> await</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> hf.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">featureExtraction</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">({</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  model: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;sentence-transformers/all-MiniLM-L6-v2&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  inputs: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;That is a happy person&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">});</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// output 是一个数字的 Float32Array</span></span></code></pre></div><h2 id="free-vs-pro" tabindex="-1">Free vs. Pro <a class="header-anchor" href="#free-vs-pro" aria-label="Permalink to &quot;Free vs. Pro&quot;">​</a></h2><ul><li><strong>免费层</strong>: 有速率限制，适合测试和开发。模型可能是“冷”的（启动慢）。</li><li><strong>Pro 账户 ($9/月)</strong>: 更高的速率限制，访问受限模型。</li><li><strong>推理端点 (Inference Endpoints)</strong>: 专用 GPU 实例（按小时付费），用于生产流量。</li></ul><h2 id="使用-transformers-js-进行本地-ai" tabindex="-1">使用 Transformers.js 进行本地 AI <a class="header-anchor" href="#使用-transformers-js-进行本地-ai" aria-label="Permalink to &quot;使用 Transformers.js 进行本地 AI&quot;">​</a></h2><p>你可以在<strong>用户浏览器中直接</strong>运行模型，无需服务器成本。</p><p><strong>查看详细指南</strong>: <a href="./../frontend-ml/transformersjs.html">前端 ML (Transformers.js)</a></p><h3 id="基础浏览器示例" tabindex="-1">基础浏览器示例 <a class="header-anchor" href="#基础浏览器示例" aria-label="Permalink to &quot;基础浏览器示例&quot;">​</a></h3><div class="language-javascript vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">javascript</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> { pipeline } </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;@xenova/transformers&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// 下载模型到浏览器缓存（仅一次）</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> classifier</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> await</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> pipeline</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;sentiment-analysis&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">);</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> result</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> await</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> classifier</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;I love using open source tools!&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">);</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// [{ label: &#39;POSITIVE&#39;, score: 0.99 }]</span></span></code></pre></div><h2 id="何时使用-hugging-face" tabindex="-1">何时使用 Hugging Face？ <a class="header-anchor" href="#何时使用-hugging-face" aria-label="Permalink to &quot;何时使用 Hugging Face？&quot;">​</a></h2><ol><li><strong>成本</strong>: 许多模型可以免费测试。</li><li><strong>隐私</strong>: 使用推理端点进行私有部署或在本地运行。</li><li><strong>专业任务</strong>: 寻找针对特定领域（生物学、法律、代码）的模型，通用 LLM 可能在这些领域表现不佳。</li></ol><h2 id="下一步" tabindex="-1">下一步 <a class="header-anchor" href="#下一步" aria-label="Permalink to &quot;下一步&quot;">​</a></h2><ul><li>了解 <a href="./streaming.html"><strong>流式传输</strong></a> 模式。</li><li>探索 <a href="./../frontend-ml/"><strong>前端 ML</strong></a> 以进行基于浏览器的 AI。</li></ul>`,23)])])}const F=i(t,[["render",l]]);export{y as __pageData,F as default};
