import{_ as a}from"./chunks/plugin-vue_export-helper.DlAUqK2U.js";import{C as o,c as s,o as t,ad as n,b as l,w as i,a as d,G as u,ae as h}from"./chunks/mermaid.Cb40Nz1P.js";import"./chunks/cytoscape.C2CwDKBM.js";import"./chunks/dayjs.C32PoDnw.js";const F=JSON.parse('{"title":"AI Model Training for Frontend Engineers","description":"","frontmatter":{},"headers":[],"relativePath":"tech/training/index.md","filePath":"tech/training/index.md"}'),g={name:"tech/training/index.md"};function c(p,e,m,f,A,b){const r=o("Mermaid");return t(),s("div",null,[e[1]||(e[1]=n('<h1 id="ai-model-training-for-frontend-engineers" tabindex="-1">AI Model Training for Frontend Engineers <a class="header-anchor" href="#ai-model-training-for-frontend-engineers" aria-label="Permalink to &quot;AI Model Training for Frontend Engineers&quot;">‚Äã</a></h1><p><strong>Important</strong>: This section explains training concepts <strong>at a high level only</strong>. As a frontend engineer, you rarely need to implement training yourself.</p><h2 id="the-golden-rule" tabindex="-1">The Golden Rule <a class="header-anchor" href="#the-golden-rule" aria-label="Permalink to &quot;The Golden Rule&quot;">‚Äã</a></h2><blockquote><p><strong>99% of frontend AI use cases should use RAG, not training.</strong></p></blockquote><p>If you&#39;re considering model training, ask yourself:</p><ul><li>Do I have 10,000+ high-quality labeled examples?</li><li>Do I have $10,000+ budget for training and experimentation?</li><li>Do I have ML engineering expertise or can I hire it?</li></ul><p><strong>If you answered &quot;no&quot; to any of these</strong>, use RAG instead.</p><hr><h2 id="when-to-use-what-decision-tree" tabindex="-1">When to Use What: Decision Tree <a class="header-anchor" href="#when-to-use-what-decision-tree" aria-label="Permalink to &quot;When to Use What: Decision Tree&quot;">‚Äã</a></h2>',9)),(t(),l(h,null,{default:i(()=>[u(r,{id:"mermaid-41",class:"mermaid",graph:"graph%20TD%0A%20%20%20%20Start%5BI%20need%20AI%20to...%5D%20--%3E%20Q1%7BUse%20my%20private%20data%3F%7D%0A%0A%20%20%20%20Q1%20--%3E%7CYes%7C%20RAG%5BUse%20RAG%5D%0A%20%20%20%20Q1%20--%3E%7CNo%7C%20Q2%7BChange%20AI%20behavior%3F%7D%0A%0A%20%20%20%20Q2%20--%3E%7CStyle%2Ftone%2Fformat%7C%20Prompt%5BAdvanced%20Prompting%5D%0A%20%20%20%20Q2%20--%3E%7CDeep%20knowledge%7C%20Q3%7BHave%2010k%2B%20examples%3F%7D%0A%0A%20%20%20%20Q3%20--%3E%7CNo%7C%20RAG2%5BStill%20use%20RAG%5D%0A%20%20%20%20Q3%20--%3E%7CYes%7C%20Q4%7BHave%20ML%20team%3F%7D%0A%0A%20%20%20%20Q4%20--%3E%7CNo%7C%20Hire%5BHire%20ML%20Engineers%5D%0A%20%20%20%20Q4%20--%3E%7CYes%7C%20Train%5BConsider%20Training%5D%0A%0A%20%20%20%20Train%20--%3E%20SFT%5BSFT%20for%20new%20knowledge%5D%0A%20%20%20%20Train%20--%3E%20RLHF%5BRLHF%20for%20behavior%5D%0A%20%20%20%20Train%20--%3E%20PEFT%5BPEFT%20to%20save%20costs%5D%0A%0A%20%20%20%20style%20RAG%20fill%3A%23d4edda%0A%20%20%20%20style%20RAG2%20fill%3A%23d4edda%0A%20%20%20%20style%20Prompt%20fill%3A%23d4edda%0A%20%20%20%20style%20Hire%20fill%3A%23fff3cd%0A%20%20%20%20style%20Train%20fill%3A%23f8d7da%0A"})]),fallback:i(()=>[...e[0]||(e[0]=[d(" Loading... ",-1)])]),_:1})),e[2]||(e[2]=n('<hr><h2 id="training-methods-comparison" tabindex="-1">Training Methods Comparison <a class="header-anchor" href="#training-methods-comparison" aria-label="Permalink to &quot;Training Methods Comparison&quot;">‚Äã</a></h2><table tabindex="0"><thead><tr><th>Method</th><th>What It Does</th><th>When Companies Use It</th><th>Frontend Relevance</th><th>Cost</th></tr></thead><tbody><tr><td><strong><a href="/learn-ai/tech/patterns/RAG.html">RAG</a></strong></td><td>Retrieve docs + inject into context</td><td>Always (first choice)</td><td>‚úÖ <strong>You implement this</strong></td><td>$</td></tr><tr><td><strong><a href="/learn-ai/tech/training/SFT.html">SFT</a></strong></td><td>Teach new knowledge via examples</td><td>Custom domains (legal, medical)</td><td>‚ùå Hire ML engineers</td><td>$$$</td></tr><tr><td><strong>RLHF</strong> üöß</td><td>Refine behavior via human feedback</td><td>ChatGPT-style alignment</td><td>‚ùå Research teams only</td><td>$$$$</td></tr><tr><td><strong>PEFT</strong> üöß</td><td>Efficient fine-tuning (LoRA)</td><td>Budget-conscious training</td><td>‚ùå ML engineers implement</td><td>$$</td></tr></tbody></table><p>üöß = Concept-only documentation (coming soon)</p><hr><h2 id="why-rag-is-your-friend" tabindex="-1">Why RAG is Your Friend <a class="header-anchor" href="#why-rag-is-your-friend" aria-label="Permalink to &quot;Why RAG is Your Friend&quot;">‚Äã</a></h2><p><strong>RAG (Retrieval-Augmented Generation)</strong> solves 99% of &quot;I need AI to know my data&quot; problems:</p><p>‚úÖ <strong>Works with any LLM</strong> - No training required ‚úÖ <strong>Updates instantly</strong> - Add new docs, they&#39;re immediately available ‚úÖ <strong>Costs pennies</strong> - Vector search + API calls vs. thousands in training ‚úÖ <strong>Debuggable</strong> - See exactly what documents were retrieved ‚úÖ <strong>Frontend-friendly</strong> - You control the entire stack</p><p><strong>Example Use Cases RAG Handles</strong>:</p><ul><li>Customer support over product docs</li><li>Internal knowledge base search</li><li>Code documentation Q&amp;A</li><li>Legal/medical document analysis</li></ul><p><strong>Read More</strong>: <a href="/learn-ai/tech/patterns/RAG.html">RAG Complete Guide</a></p><hr><h2 id="when-training-actually-makes-sense" tabindex="-1">When Training Actually Makes Sense <a class="header-anchor" href="#when-training-actually-makes-sense" aria-label="Permalink to &quot;When Training Actually Makes Sense&quot;">‚Äã</a></h2><p>You should only consider training if you meet <strong>ALL</strong> of these criteria:</p><h3 id="for-supervised-fine-tuning-sft" tabindex="-1">For Supervised Fine-Tuning (SFT) <a class="header-anchor" href="#for-supervised-fine-tuning-sft" aria-label="Permalink to &quot;For Supervised Fine-Tuning (SFT)&quot;">‚Äã</a></h3><ul><li>[ ] You need the AI to learn <strong>domain-specific knowledge</strong> that doesn&#39;t exist in public training data</li><li>[ ] You have <strong>10,000+ high-quality labeled examples</strong> (not just documents - actual input/output pairs)</li><li>[ ] RAG is too slow or expensive for your use case</li><li>[ ] You have budget for <strong>$5,000-$50,000</strong> in training costs</li><li>[ ] You have ML engineers who can implement and debug this</li></ul><p><strong>Example</strong>: A medical company training an LLM to interpret proprietary lab reports using 50,000 annotated examples.</p><h3 id="for-rlhf-reinforcement-learning-from-human-feedback" tabindex="-1">For RLHF (Reinforcement Learning from Human Feedback) <a class="header-anchor" href="#for-rlhf-reinforcement-learning-from-human-feedback" aria-label="Permalink to &quot;For RLHF (Reinforcement Learning from Human Feedback)&quot;">‚Äã</a></h3><ul><li>[ ] You need to change <strong>behavior</strong> (tone, style, safety) not add knowledge</li><li>[ ] You have hundreds of hours of human feedback data</li><li>[ ] You have a research team with RLHF expertise</li><li>[ ] Budget: <strong>$50,000+</strong></li></ul><p><strong>Example</strong>: OpenAI aligning GPT-4 to refuse harmful requests.</p><h3 id="for-peft-parameter-efficient-fine-tuning" tabindex="-1">For PEFT (Parameter-Efficient Fine-Tuning) <a class="header-anchor" href="#for-peft-parameter-efficient-fine-tuning" aria-label="Permalink to &quot;For PEFT (Parameter-Efficient Fine-Tuning)&quot;">‚Äã</a></h3><ul><li>[ ] You&#39;re already doing SFT but need to reduce costs</li><li>[ ] You need to deploy multiple specialized models</li><li>[ ] You have ML engineers familiar with LoRA/QLoRA</li></ul><p><strong>Example</strong>: Startups creating customer-specific model variants without full fine-tuning costs.</p><hr><h2 id="the-when-to-hire-ml-engineers-checklist" tabindex="-1">The &quot;When to Hire ML Engineers&quot; Checklist <a class="header-anchor" href="#the-when-to-hire-ml-engineers-checklist" aria-label="Permalink to &quot;The &quot;When to Hire ML Engineers&quot; Checklist&quot;">‚Äã</a></h2><p>If you&#39;re a frontend engineer and answered &quot;yes&quot; to any of these, it&#39;s time to involve ML specialists:</p><ul><li>[ ] RAG isn&#39;t accurate enough even after optimization</li><li>[ ] You need the model to &quot;memorize&quot; domain knowledge (SFT)</li><li>[ ] You&#39;re spending &gt;$10k/month on API calls and training might reduce costs</li><li>[ ] You need to deploy models on-device or in restrictive environments</li><li>[ ] Your company wants a proprietary AI advantage (custom model)</li></ul><p><strong>What You Should Do First</strong>:</p><ol><li>Exhaust all RAG optimizations (hybrid search, reranking, better chunking)</li><li>Try advanced prompting techniques (few-shot, chain-of-thought)</li><li>Test with multiple LLM providers (Claude, GPT-4, Gemini)</li><li>Calculate ROI: Will training savings exceed $50k+ implementation cost?</li></ol><hr><h2 id="training-concepts-overview" tabindex="-1">Training Concepts Overview <a class="header-anchor" href="#training-concepts-overview" aria-label="Permalink to &quot;Training Concepts Overview&quot;">‚Äã</a></h2><h3 id="supervised-fine-tuning-sft" tabindex="-1">Supervised Fine-Tuning (SFT) <a class="header-anchor" href="#supervised-fine-tuning-sft" aria-label="Permalink to &quot;Supervised Fine-Tuning (SFT)&quot;">‚Äã</a></h3><p><strong>What</strong>: Train a model on input-output examples to teach new knowledge or tasks.</p><p><strong>Pros</strong>:</p><ul><li>Model &quot;learns&quot; domain-specific knowledge</li><li>Can improve accuracy over RAG in narrow domains</li><li>Responses can be faster (no retrieval step)</li></ul><p><strong>Cons</strong>:</p><ul><li>Requires 1,000-100,000+ examples</li><li>Expensive ($1k-$100k depending on scale)</li><li>Static - new data requires retraining</li><li>Hard to debug when it goes wrong</li></ul><p><strong>Read More</strong>: <a href="/learn-ai/tech/training/SFT.html">SFT Guide</a></p><hr><h3 id="rlhf-reinforcement-learning-from-human-feedback" tabindex="-1">RLHF (Reinforcement Learning from Human Feedback) <a class="header-anchor" href="#rlhf-reinforcement-learning-from-human-feedback" aria-label="Permalink to &quot;RLHF (Reinforcement Learning from Human Feedback)&quot;">‚Äã</a></h3><p><strong>What</strong>: Human annotators rank model outputs (good/bad), and the model learns to prefer &quot;good&quot; responses.</p><p><strong>Used By</strong>: ChatGPT, Claude, Gemini (all major LLMs)</p><p><strong>Frontend Relevance</strong>: You&#39;ll never implement this. It&#39;s how OpenAI/Anthropic create safe, helpful models that you consume via APIs.</p><p><strong>Concept-only documentation coming soon</strong></p><hr><h3 id="peft-parameter-efficient-fine-tuning" tabindex="-1">PEFT (Parameter-Efficient Fine-Tuning) <a class="header-anchor" href="#peft-parameter-efficient-fine-tuning" aria-label="Permalink to &quot;PEFT (Parameter-Efficient Fine-Tuning)&quot;">‚Äã</a></h3><p><strong>What</strong>: Techniques like LoRA that train only a small subset of model parameters instead of the full model.</p><p><strong>Why It Exists</strong>: Full fine-tuning GPT-3.5 costs $10k+. LoRA can do it for $100.</p><p><strong>When Companies Use It</strong>:</p><ul><li>Creating customer-specific model variants</li><li>Rapid experimentation with limited budget</li><li>Deploying multiple specialized models</li></ul><p><strong>Frontend Relevance</strong>: If your company has ML engineers doing SFT, they might use PEFT to reduce costs. You&#39;ll consume the model via API regardless.</p><p><strong>Concept-only documentation coming soon</strong></p><hr><h2 id="training-providers-if-you-must" tabindex="-1">Training Providers (If You Must) <a class="header-anchor" href="#training-providers-if-you-must" aria-label="Permalink to &quot;Training Providers (If You Must)&quot;">‚Äã</a></h2><p>If you&#39;ve decided training is necessary, these providers offer no-code/low-code solutions:</p><table tabindex="0"><thead><tr><th>Provider</th><th>Best For</th><th>Starting Cost</th></tr></thead><tbody><tr><td><strong>OpenAI Fine-Tuning</strong></td><td>GPT-3.5/4 fine-tuning</td><td>~$1,200 (training) + usage</td></tr><tr><td><strong>Anthropic</strong></td><td>Claude fine-tuning (limited availability)</td><td>Contact sales</td></tr><tr><td><strong>HuggingFace AutoTrain</strong></td><td>Open models (Llama, Mistral)</td><td>$100-$5,000</td></tr><tr><td><strong>Replicate</strong></td><td>One-click fine-tuning</td><td>$0.50-$5 per training run</td></tr></tbody></table><p><strong>Note</strong>: Even with these tools, you need ML expertise to:</p><ul><li>Prepare quality training data</li><li>Evaluate model performance</li><li>Debug issues</li><li>Decide when to stop training</li></ul><hr><h2 id="the-frontend-engineer-s-training-mindset" tabindex="-1">The Frontend Engineer&#39;s Training Mindset <a class="header-anchor" href="#the-frontend-engineer-s-training-mindset" aria-label="Permalink to &quot;The Frontend Engineer&#39;s Training Mindset&quot;">‚Äã</a></h2><p><strong>Your role</strong>: Understand these concepts exist so you can:</p><ul><li>Have informed conversations with ML teams</li><li>Make build-vs-buy decisions</li><li>Know when RAG is sufficient (99% of the time)</li><li>Recognize when to escalate to specialists</li></ul><p><strong>Your job is NOT</strong>:</p><ul><li>Implementing training pipelines</li><li>Debugging gradient descent</li><li>Choosing hyperparameters</li><li>Managing GPU infrastructure</li></ul><p><strong>Your job IS</strong>:</p><ul><li>Building great RAG systems</li><li>Mastering prompt engineering</li><li>Integrating trained models via APIs</li><li>Creating UX for AI features</li></ul><hr><h2 id="next-steps" tabindex="-1">Next Steps <a class="header-anchor" href="#next-steps" aria-label="Permalink to &quot;Next Steps&quot;">‚Äã</a></h2><h3 id="for-most-frontend-engineers" tabindex="-1">For Most Frontend Engineers <a class="header-anchor" href="#for-most-frontend-engineers" aria-label="Permalink to &quot;For Most Frontend Engineers&quot;">‚Äã</a></h3><ol><li>Master RAG: <a href="/learn-ai/tech/patterns/RAG.html">RAG Complete Guide</a></li><li>Optimize prompts: <a href="/learn-ai/tech/prompt/">Prompt Engineering</a></li><li>Learn structured output: <a href="/learn-ai/tech/structured-output.html">Type-Safe AI</a> üöß</li></ol><h3 id="if-you-re-considering-training" tabindex="-1">If You&#39;re Considering Training <a class="header-anchor" href="#if-you-re-considering-training" aria-label="Permalink to &quot;If You&#39;re Considering Training&quot;">‚Äã</a></h3><ol><li>Read <a href="/learn-ai/tech/training/SFT.html">SFT Guide</a> to understand requirements</li><li>Audit your data: Do you have 10k+ quality examples?</li><li>Calculate costs: Compare RAG optimization vs. training investment</li><li>Consult with ML engineers before committing</li></ol><h3 id="if-you-re-building-ai-products" tabindex="-1">If You&#39;re Building AI Products <a class="header-anchor" href="#if-you-re-building-ai-products" aria-label="Permalink to &quot;If You&#39;re Building AI Products&quot;">‚Äã</a></h3><ol><li>Start with RAG always</li><li>Measure: Is RAG accuracy &lt;90% after optimization?</li><li>Explore: Can better prompts/models solve it?</li><li>Only then: Consider training with ML team</li></ol><hr><h2 id="summary" tabindex="-1">Summary <a class="header-anchor" href="#summary" aria-label="Permalink to &quot;Summary&quot;">‚Äã</a></h2><ul><li><strong>99% of use cases ‚Üí Use RAG</strong> (no training needed)</li><li><strong>Training is expensive</strong> ($5k-$100k) and requires ML expertise</li><li><strong>Frontend engineers</strong> should understand concepts, not implement training</li><li><strong>When in doubt</strong>, optimize RAG before considering training</li></ul><p><strong>The golden rule</strong>: If you can solve it with RAG, don&#39;t train. If you can solve it with better prompts, don&#39;t use RAG.</p><hr><h2 id="additional-resources" tabindex="-1">Additional Resources <a class="header-anchor" href="#additional-resources" aria-label="Permalink to &quot;Additional Resources&quot;">‚Äã</a></h2><ul><li><a href="https://www.pinecone.io/learn/rag-vs-finetuning/" target="_blank" rel="noreferrer">RAG vs Fine-Tuning: When to Use Each</a> (External)</li><li><a href="https://platform.openai.com/docs/guides/fine-tuning" target="_blank" rel="noreferrer">OpenAI Fine-Tuning Guide</a> (External)</li><li><a href="https://www.anthropic.com/research/economics" target="_blank" rel="noreferrer">The Economics of LLM Fine-Tuning</a> (External - Example)</li></ul><p><strong>Questions?</strong> If you&#39;re unsure whether to use RAG or training, <a href="https://github.com/zenheart/learn-ai/discussions" target="_blank" rel="noreferrer">open a discussion</a>.</p>',82))])}const q=a(g,[["render",c]]);export{F as __pageData,q as default};
