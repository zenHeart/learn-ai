import{_ as n}from"./chunks/plugin-vue_export-helper.DlAUqK2U.js";import{C as s,c as r,o as e,ad as o,b as l,w as a,a as d,G as g,ae as h}from"./chunks/mermaid.Cb40Nz1P.js";import"./chunks/cytoscape.C2CwDKBM.js";import"./chunks/dayjs.C32PoDnw.js";const C=JSON.parse('{"title":"API Integration Guide","description":"","frontmatter":{},"headers":[],"relativePath":"integration/apis/index.md","filePath":"integration/apis/index.md"}'),p={name:"integration/apis/index.md"};function u(c,t,m,f,x,y){const i=s("Mermaid");return e(),r("div",null,[t[1]||(t[1]=o('<h1 id="api-integration-guide" tabindex="-1">API Integration Guide <a class="header-anchor" href="#api-integration-guide" aria-label="Permalink to &quot;API Integration Guide&quot;">‚Äã</a></h1><p><strong>Prerequisite Knowledge</strong>: <a href="./../../tech/fundamentals/LLM.html">LLM Fundamentals</a></p><h2 id="overview" tabindex="-1">Overview <a class="header-anchor" href="#overview" aria-label="Permalink to &quot;Overview&quot;">‚Äã</a></h2><p>Integrating AI into your application starts with choosing the right Model Provider. While there are dozens of options, 95% of production applications today build on top of three core providers: <strong>OpenAI</strong>, <strong>Anthropic</strong>, and <strong>Google</strong>.</p><p>This section guides you through connecting these powerful models to your frontend applications.</p><h2 id="provider-comparison-matrix" tabindex="-1">Provider Comparison Matrix <a class="header-anchor" href="#provider-comparison-matrix" aria-label="Permalink to &quot;Provider Comparison Matrix&quot;">‚Äã</a></h2><table tabindex="0"><thead><tr><th style="text-align:left;">Feature</th><th style="text-align:left;">OpenAI (GPT-4o)</th><th style="text-align:left;">Anthropic (Claude 3.5 Sonnet)</th><th style="text-align:left;">Google (Gemini 1.5 Pro)</th></tr></thead><tbody><tr><td style="text-align:left;"><strong>Best For</strong></td><td style="text-align:left;">General Purpose, Function Calling, Structured Data</td><td style="text-align:left;">Coding, Reasoning, Creative Writing</td><td style="text-align:left;">Long Context (2M tokens), Multimodal (Video)</td></tr><tr><td style="text-align:left;"><strong>Speed</strong></td><td style="text-align:left;">‚ö°Ô∏è‚ö°Ô∏è‚ö°Ô∏è‚ö°Ô∏è (Fast)</td><td style="text-align:left;">‚ö°Ô∏è‚ö°Ô∏è‚ö°Ô∏è (Moderate)</td><td style="text-align:left;">‚ö°Ô∏è‚ö°Ô∏è‚ö°Ô∏è (Moderate)</td></tr><tr><td style="text-align:left;"><strong>Cost</strong></td><td style="text-align:left;">üí∞üí∞ (Moderate)</td><td style="text-align:left;">üí∞üí∞ (Moderate)</td><td style="text-align:left;">üí∞ (Low)</td></tr><tr><td style="text-align:left;"><strong>Context Window</strong></td><td style="text-align:left;">128k Tokens</td><td style="text-align:left;">200k Tokens</td><td style="text-align:left;">2M Tokens</td></tr><tr><td style="text-align:left;"><strong>Tool Use</strong></td><td style="text-align:left;">Excellent</td><td style="text-align:left;">Excellent</td><td style="text-align:left;">Good</td></tr><tr><td style="text-align:left;"><strong>Ecosystem</strong></td><td style="text-align:left;">Massive (Assistants API, Realtime API)</td><td style="text-align:left;">Strong (Artifacts, Computer Use)</td><td style="text-align:left;">Growing (Deep Google Integration)</td></tr></tbody></table><hr><h2 id="decision-tree-which-api-should-i-use" tabindex="-1">Decision Tree: Which API Should I Use? <a class="header-anchor" href="#decision-tree-which-api-should-i-use" aria-label="Permalink to &quot;Decision Tree: Which API Should I Use?&quot;">‚Äã</a></h2>',9)),(e(),l(h,null,{default:a(()=>[g(i,{id:"mermaid-126",class:"mermaid",graph:"graph%20TD%0A%20%20%20%20A%5BStart%5D%20--%3E%20B%7BNeed%20to%20analyze%20video%20or%20%3Cbr%3Emassive%20docs%3F%7D%0A%20%20%20%20B%20--%20Yes%20--%3E%20C%5BGoogle%20Gemini%201.5%20Pro%5D%0A%20%20%20%20B%20--%20No%20--%3E%20D%7BComplex%20coding%20or%20%3Cbr%3Enuanced%20writing%3F%7D%0A%20%20%20%20D%20--%20Yes%20--%3E%20E%5BAnthropic%20Claude%203.5%20Sonnet%5D%0A%20%20%20%20D%20--%20No%20--%3E%20F%7BNeed%20structured%20JSON%20%3Cbr%3Eor%20robust%20tools%3F%7D%0A%20%20%20%20F%20--%20Yes%20--%3E%20G%5BOpenAI%20GPT-4o%5D%0A%20%20%20%20F%20--%20No%20--%3E%20H%5BOpenAI%20GPT-4o-mini%20%3Cbr%3E(Cheapest%2FFastest)%5D%0A"})]),fallback:a(()=>[...t[0]||(t[0]=[d(" Loading... ",-1)])]),_:1})),t[2]||(t[2]=o('<hr><h2 id="cost-comparison-estimates" tabindex="-1">Cost Comparison (Estimates) <a class="header-anchor" href="#cost-comparison-estimates" aria-label="Permalink to &quot;Cost Comparison (Estimates)&quot;">‚Äã</a></h2><p>Prices are per 1 Million Tokens (approx. 750,000 words). <em>Prices subject to change. Last updated: Jan 2026.</em></p><table tabindex="0"><thead><tr><th style="text-align:left;">Model</th><th style="text-align:left;">Input Cost</th><th style="text-align:left;">Output Cost</th><th style="text-align:left;">Total for ~1000 requests</th></tr></thead><tbody><tr><td style="text-align:left;"><strong>GPT-4o</strong></td><td style="text-align:left;">$2.50</td><td style="text-align:left;">$10.00</td><td style="text-align:left;">~$5.00</td></tr><tr><td style="text-align:left;"><strong>Claude 3.5 Sonnet</strong></td><td style="text-align:left;">$3.00</td><td style="text-align:left;">$15.00</td><td style="text-align:left;">~$6.00</td></tr><tr><td style="text-align:left;"><strong>Gemini 1.5 Pro</strong></td><td style="text-align:left;">$1.25</td><td style="text-align:left;">$5.00</td><td style="text-align:left;">~$2.50</td></tr><tr><td style="text-align:left;"><strong>GPT-4o-mini</strong></td><td style="text-align:left;">$0.15</td><td style="text-align:left;">$0.60</td><td style="text-align:left;">~$0.30</td></tr></tbody></table><blockquote><p><strong>Takeaway</strong>: For simple tasks (summarization, simple chat), use <strong>GPT-4o-mini</strong>. It is 20x cheaper than the flagship models.</p></blockquote><hr><h2 id="detailed-integration-guides" tabindex="-1">Detailed Integration Guides <a class="header-anchor" href="#detailed-integration-guides" aria-label="Permalink to &quot;Detailed Integration Guides&quot;">‚Äã</a></h2><p>Ready to write code? Follow these specific guides:</p><ul><li><a href="./openai.html"><strong>OpenAI Guide</strong></a>: The industry standard. Covers setup, streaming, and tool calling.</li><li><a href="./anthropic.html"><strong>Anthropic Guide</strong></a>: Best for &quot;smart&quot; tasks. Covers the Anthropic SDK.</li><li><a href="./huggingface.html"><strong>HuggingFace Guide</strong></a>: For open-source models and free inference APIs.</li></ul><hr><h2 id="rate-limits-quotas" tabindex="-1">Rate Limits &amp; Quotas <a class="header-anchor" href="#rate-limits-quotas" aria-label="Permalink to &quot;Rate Limits &amp; Quotas&quot;">‚Äã</a></h2><p>When moving to production, you will hit limits.</p><p><strong>Common Limits</strong>:</p><ol><li><strong>RPM (Requests Per Minute)</strong>: How many API calls you can make.</li><li><strong>TPM (Tokens Per Minute)</strong>: How much text you can send/receive.</li></ol><p><strong>Handling Limits</strong>:</p><ul><li><strong>Exponential Backoff</strong>: If you get a <code>429 Too Many Requests</code>, wait 1s, then 2s, then 4s...</li><li><strong>Tier Upgrades</strong>: Most providers increase limits as you spend more (e.g., OpenAI Usage Tiers).</li><li><strong>Load Balancing</strong>: Advanced users rotate keys or providers.</li></ul><hr><h2 id="next-steps" tabindex="-1">Next Steps <a class="header-anchor" href="#next-steps" aria-label="Permalink to &quot;Next Steps&quot;">‚Äã</a></h2><ol><li><strong>Get an API Key</strong> from your chosen provider.</li><li><strong>Install the SDK</strong> (<code>npm install openai</code> or <code>npm install @anthropic-ai/sdk</code>).</li><li><strong>Make your first call</strong> following our <a href="./openai.html">OpenAI Guide</a>.</li></ol>',19))])}const I=n(p,[["render",u]]);export{C as __pageData,I as default};
