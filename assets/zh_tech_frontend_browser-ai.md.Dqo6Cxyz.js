import{_ as i}from"./chunks/plugin-vue_export-helper.DlAUqK2U.js";import{c as a,o as t,ad as n}from"./chunks/mermaid.Cb40Nz1P.js";import"./chunks/cytoscape.C2CwDKBM.js";import"./chunks/dayjs.C32PoDnw.js";const y=JSON.parse('{"title":"浏览器 AI (客户端)","description":"","frontmatter":{},"headers":[],"relativePath":"zh/tech/frontend/browser-ai.md","filePath":"zh/tech/frontend/browser-ai.md"}'),e={name:"zh/tech/frontend/browser-ai.md"};function l(h,s,r,p,k,d){return t(),a("div",null,[...s[0]||(s[0]=[n(`<h1 id="浏览器-ai-客户端" tabindex="-1">浏览器 AI (客户端) <a class="header-anchor" href="#浏览器-ai-客户端" aria-label="Permalink to &quot;浏览器 AI (客户端)&quot;">​</a></h1><p>在<strong>浏览器中直接</strong>运行 AI (客户端推理) 是终极的隐私和零延迟解决方案。无需服务器，无 API 成本。</p><h2 id="工具-transformers-js" tabindex="-1">工具：Transformers.js <a class="header-anchor" href="#工具-transformers-js" aria-label="Permalink to &quot;工具：Transformers.js&quot;">​</a></h2><p><strong>Transformers.js</strong> 允许你使用 ONNX Runtime 在 JavaScript 中运行 Hugging Face 模型。</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">npm</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> @xenova/transformers</span></span></code></pre></div><h2 id="工作原理" tabindex="-1">工作原理 <a class="header-anchor" href="#工作原理" aria-label="Permalink to &quot;工作原理&quot;">​</a></h2><ol><li><strong>下载</strong>: 浏览器下载模型权重（缓存在 IndexedDB 中）。</li><li><strong>初始化</strong>: ONNX Runtime 启动会话。</li><li><strong>推理</strong>: 输入 -&gt; 模型 -&gt; 输出。</li></ol><h2 id="代码示例-情感分析" tabindex="-1">代码示例：情感分析 <a class="header-anchor" href="#代码示例-情感分析" aria-label="Permalink to &quot;代码示例：情感分析&quot;">​</a></h2><div class="language-javascript vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">javascript</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> { pipeline } </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;@xenova/transformers&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">async</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> function</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> analyze</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">() {</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  // 下载 &#39;Xenova/distilbert-base-uncased-finetuned-sst-2-english&#39; (~40MB)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> classifier</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> await</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> pipeline</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;sentiment-analysis&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">);</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  </span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> result</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> await</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> classifier</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;This app is amazing!&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">);</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  // [{ label: &#39;POSITIVE&#39;, score: 0.99 }]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><h2 id="webgpu-加速" tabindex="-1">WebGPU 加速 <a class="header-anchor" href="#webgpu-加速" aria-label="Permalink to &quot;WebGPU 加速&quot;">​</a></h2><p>默认情况下，它使用 WASM (CPU)。为了获得更快的性能（特别是对于生成模型如 Whisper 或微型 LLM），请使用 WebGPU。</p><div class="language-javascript vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">javascript</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> { pipeline, env } </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;@xenova/transformers&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// 跳过本地检查</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">env.allowLocalModels </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> false</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">env.useBrowserCache </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> true</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> generator</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> await</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> pipeline</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;text-generation&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Xenova/llama2-7b-int4&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, {</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  device: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;webgpu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// 使用 GPU!</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">});</span></span></code></pre></div><h2 id="用例" tabindex="-1">用例 <a class="header-anchor" href="#用例" aria-label="Permalink to &quot;用例&quot;">​</a></h2><ol><li><strong>隐私优先的应用</strong>: 分析医疗/法律文本而不将其发送到云端。</li><li><strong>离线能力</strong>: 在飞机上也能工作的 AI 功能。</li><li><strong>实时音频</strong>: 在浏览器中使用 <strong>Whisper</strong> 进行听写。</li><li><strong>图像处理</strong>: 用户照片的背景移除或对象检测。</li></ol><h2 id="性能与权衡" tabindex="-1">性能与权衡 <a class="header-anchor" href="#性能与权衡" aria-label="Permalink to &quot;性能与权衡&quot;">​</a></h2><table tabindex="0"><thead><tr><th style="text-align:left;">特性</th><th style="text-align:left;">服务端 (API)</th><th style="text-align:left;">客户端 (浏览器)</th></tr></thead><tbody><tr><td style="text-align:left;"><strong>模型大小</strong></td><td style="text-align:left;">巨大 (GPT-4)</td><td style="text-align:left;">微型 (DistilBERT, Phi-2)</td></tr><tr><td style="text-align:left;"><strong>质量</strong></td><td style="text-align:left;">优秀</td><td style="text-align:left;">特定任务良好</td></tr><tr><td style="text-align:left;"><strong>延迟</strong></td><td style="text-align:left;">依赖网络</td><td style="text-align:left;">零 (加载后)</td></tr><tr><td style="text-align:left;"><strong>隐私</strong></td><td style="text-align:left;">数据离开设备</td><td style="text-align:left;">数据留在设备上</td></tr><tr><td style="text-align:left;"><strong>电池</strong></td><td style="text-align:left;">低影响</td><td style="text-align:left;">高影响 (GPU 使用)</td></tr></tbody></table><h2 id="下一步" tabindex="-1">下一步 <a class="header-anchor" href="#下一步" aria-label="Permalink to &quot;下一步&quot;">​</a></h2><ul><li>查看 <strong><a href="https://onnxruntime.ai/" target="_blank" rel="noreferrer">ONNX Runtime</a></strong> 文档。</li><li>查看 <strong><a href="./../../examples/04-browser-ai/README.html">示例项目</a></strong> (即将推出)。</li></ul>`,18)])])}const F=i(e,[["render",l]]);export{y as __pageData,F as default};
